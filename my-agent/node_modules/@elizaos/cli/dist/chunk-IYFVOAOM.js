
import { createRequire } from 'module';
const require = createRequire(import.meta.url);

import {
  displayBunInstallationTipCompact,
  runBunCommand
} from "./chunk-RIAWNDYI.js";
import {
  emoji
} from "./chunk-KB3JDWUI.js";
import {
  getAgentRuntimeUrl,
  getAgentsBaseUrl
} from "./chunk-F24MS2YR.js";
import {
  __require
} from "./chunk-AQ6OMR2A.js";

// src/utils/build-project.ts
import * as fs3 from "fs";
import * as path4 from "path";
import { logger as logger3 } from "@elizaos/core";
import { execa as execa2 } from "execa";

// src/utils/directory-detection.ts
import * as fs2 from "fs";
import * as path3 from "path";

// src/utils/user-environment.ts
import os from "os";
import fs from "fs/promises";
import path2 from "path";
import * as semver from "semver";
import { fileURLToPath } from "url";
import { logger as logger2 } from "@elizaos/core";
import { existsSync as existsSync2, statSync, readFileSync } from "fs";
import { execSync } from "child_process";

// src/utils/resolve-utils.ts
import dotenv from "dotenv";
import { existsSync } from "fs";
import path from "path";
function expandTildePath(filepath, projectRootForTilde = process.cwd()) {
  if (filepath && filepath.startsWith("~")) {
    return path.join(projectRootForTilde, filepath.slice(1));
  }
  return filepath;
}
function resolveEnvFile(startDir = process.cwd(), boundaryDir) {
  const root = path.resolve(startDir);
  const stopAt = boundaryDir ? path.resolve(boundaryDir) : void 0;
  if (!stopAt) {
    return path.join(root, ".env");
  }
  let current = root;
  while (true) {
    const candidate = path.join(current, ".env");
    if (existsSync(candidate)) {
      return candidate;
    }
    if (stopAt && current === stopAt) {
      break;
    }
    const parent = path.dirname(current);
    if (parent === current) {
      break;
    }
    current = parent;
  }
  return path.join(root, ".env");
}
async function resolvePgliteDir(dir, fallbackDir) {
  const userEnv = UserEnvironment.getInstance();
  const pathsInfo = await userEnv.getPathInfo();
  const projectRoot = pathsInfo.monorepoRoot || process.cwd();
  if (pathsInfo.envFilePath && existsSync(pathsInfo.envFilePath)) {
    dotenv.config({ path: pathsInfo.envFilePath });
  }
  const defaultBaseDir = path.join(projectRoot, ".eliza", ".elizadb");
  const base = dir ?? process.env.PGLITE_DATA_DIR ?? fallbackDir ?? defaultBaseDir;
  const resolved = expandTildePath(base, projectRoot);
  const legacyPath = path.join(projectRoot, ".elizadb");
  if (resolved === legacyPath) {
    const newPath = path.join(projectRoot, ".eliza", ".elizadb");
    process.env.PGLITE_DATA_DIR = newPath;
    return newPath;
  }
  return resolved;
}

// src/utils/auto-install-bun.ts
import { logger } from "@elizaos/core";
import { execa } from "execa";
async function autoInstallBun() {
  const platform = process.platform;
  try {
    await execa("bun", ["--version"], { stdio: "ignore" });
    return true;
  } catch {
  }
  logger.info(`${emoji.rocket("Bun is required for ElizaOS CLI. Installing automatically...")}`);
  try {
    if (platform === "win32") {
      logger.info("Installing Bun on Windows...");
      await execa("powershell", ["-c", "irm bun.sh/install.ps1 | iex"], {
        stdio: "inherit"
      });
    } else {
      logger.info("Installing Bun on Linux/macOS...");
      await execa("sh", ["-c", "curl -fsSL https://bun.sh/install | bash"], {
        stdio: "inherit"
      });
    }
    const bunPath = platform === "win32" ? `${process.env.USERPROFILE}\\.bun\\bin` : `${process.env.HOME}/.bun/bin`;
    if (bunPath && !process.env.PATH?.includes(bunPath)) {
      process.env.PATH = `${bunPath}${platform === "win32" ? ";" : ":"}${process.env.PATH}`;
    }
    await execa("bun", ["--version"], { stdio: "ignore" });
    logger.success(`${emoji.success("Bun installed successfully!")}`);
    return true;
  } catch (error) {
    logger.error(`${emoji.error("Failed to automatically install Bun:")}`);
    logger.error(`Error: ${error instanceof Error ? error.message : String(error)}`);
    logger.info(`
${emoji.info("Please install Bun manually:")}`);
    if (platform === "win32") {
      logger.info('   Windows: powershell -c "irm bun.sh/install.ps1 | iex"');
    } else {
      logger.info("   Linux/macOS: curl -fsSL https://bun.sh/install | bash");
      if (platform === "darwin") {
        logger.info("   macOS (Homebrew): brew install bun");
      }
    }
    logger.info(`
${emoji.link("More options: https://bun.sh/docs/installation")}`);
    logger.info(
      `
${emoji.tip("After installation, restart your terminal or source your shell profile")}`
    );
    return false;
  }
}
function shouldAutoInstall() {
  if (process.env.CI === "true" || process.env.CI === "1") {
    return false;
  }
  if (process.env.ELIZA_NO_AUTO_INSTALL === "true") {
    return false;
  }
  if (process.argv.includes("--no-auto-install")) {
    return false;
  }
  return true;
}

// src/utils/user-environment.ts
var UserEnvironment = class _UserEnvironment {
  static getInstance = () => _UserEnvironment.instance;
  static getInstanceInfo = () => _UserEnvironment.instance.getInfo();
  static instance = new _UserEnvironment();
  cachedInfo = {};
  // Cache per directory
  constructor() {
  }
  /**
   * Gets operating system information
   */
  async getOSInfo() {
    logger2.debug("[UserEnvironment] Detecting OS information");
    return {
      platform: os.platform(),
      release: os.release(),
      arch: os.arch(),
      type: os.type(),
      version: os.version(),
      homedir: os.homedir()
    };
  }
  /**
   * Gets CLI version and package information
   */
  async getCLIInfo() {
    logger2.debug("[UserEnvironment] Getting CLI information");
    try {
      const __filename2 = fileURLToPath(import.meta.url);
      const __dirname2 = path2.dirname(__filename2);
      const packageJsonPath = path2.resolve(__dirname2, "../package.json");
      if (!existsSync2(packageJsonPath)) {
        throw new Error(`CLI package.json not found at ${packageJsonPath}`);
      }
      const packageJsonContent = await fs.readFile(packageJsonPath, "utf-8");
      const packageJson = JSON.parse(packageJsonContent);
      return {
        version: packageJson.version || "0.0.0",
        name: packageJson.name || "@elizaos/cli",
        path: process.argv[1] || ""
      };
    } catch (error) {
      logger2.warn(
        `[UserEnvironment] Error getting CLI info: ${error instanceof Error ? error.message : String(error)}`
      );
      return {
        version: "0.0.0",
        name: "@elizaos/cli",
        path: process.argv[1] || ""
      };
    }
  }
  /**
   * Detects the active package manager - always returns bun for ElizaOS CLI
   */
  async getPackageManagerInfo() {
    logger2.debug("[UserEnvironment] Using bun as the package manager for ElizaOS CLI");
    const isNpx = process.env.npm_execpath?.includes("npx");
    const isBunx = process.argv[0]?.includes("bun");
    let version = null;
    try {
      const { stdout } = await import("execa").then(({ execa: execa9 }) => execa9("bun", ["--version"]));
      version = stdout.trim();
      logger2.debug(`[UserEnvironment] Bun version: ${version}`);
    } catch (e) {
      logger2.debug(
        `[UserEnvironment] Could not get bun version: ${e instanceof Error ? e.message : String(e)}`
      );
      if (shouldAutoInstall()) {
        logger2.info(`${emoji.info("Attempting to automatically install Bun...")}`);
        const installSuccess = await autoInstallBun();
        if (installSuccess) {
          try {
            const { stdout } = await import("execa").then(
              ({ execa: execa9 }) => execa9("bun", ["--version"])
            );
            version = stdout.trim();
            logger2.debug(`[UserEnvironment] Bun version after auto-install: ${version}`);
          } catch (retryError) {
            logger2.error(
              `Failed to verify Bun installation after auto-install: ${retryError instanceof Error ? retryError.message : String(retryError)}`
            );
          }
        }
      }
      if (!version) {
        const platform = process.platform;
        logger2.error(
          `${emoji.error("Bun is required for ElizaOS CLI but is not installed or not found in PATH.")}`
        );
        logger2.error("");
        logger2.error(
          `${emoji.rocket("Install Bun using the appropriate command for your system:")}`
        );
        logger2.error("");
        if (platform === "win32") {
          logger2.error('   Windows: powershell -c "irm bun.sh/install.ps1 | iex"');
        } else {
          logger2.error("   Linux/macOS: curl -fsSL https://bun.sh/install | bash");
          if (platform === "darwin") {
            logger2.error("   macOS (Homebrew): brew install bun");
          }
        }
        logger2.error("");
        logger2.error("   More options: https://bun.sh/docs/installation");
        logger2.error("   After installation, restart your terminal or source your shell profile");
        logger2.error("");
        logger2.error("\u{1F534} Exiting: Bun installation is required to continue.");
        process.exit(1);
      }
    }
    const packageName = "@elizaos/cli";
    let isGlobalCheck = false;
    try {
      if (!isNpx && !isBunx) {
        const command = process.platform === "win32" ? `bun pm ls -g | findstr "${packageName}"` : `bun pm ls -g | grep -q "${packageName}"`;
        execSync(command, { stdio: "ignore" });
        isGlobalCheck = true;
      }
    } catch (error) {
      isGlobalCheck = false;
    }
    const isGlobal = isGlobalCheck || process.env.NODE_ENV === "global";
    return {
      name: "bun",
      version,
      global: isGlobal,
      isNpx: !!isNpx,
      isBunx
    };
  }
  /**
   * Finds the monorepo root by traversing upwards from a starting directory,
   * looking for a marker directory ('packages/core').
   *
   * @param startDir The directory to start searching from.
   * @returns The path to the monorepo root if found, otherwise null.
   */
  findMonorepoRoot(startDir) {
    let currentDir = path2.resolve(startDir);
    let levels = 0;
    const MAX_LEVELS = 10;
    while (levels < MAX_LEVELS) {
      const corePackagePath = path2.join(currentDir, "packages", "core");
      if (existsSync2(corePackagePath)) {
        try {
          const stats = statSync(corePackagePath);
          if (stats.isDirectory()) {
            const packageJsonPath = path2.join(currentDir, "package.json");
            if (existsSync2(packageJsonPath)) {
              const packageJsonContent = readFileSync(packageJsonPath, "utf8");
              const packageJson = JSON.parse(packageJsonContent);
              if (packageJson.name?.includes("eliza") || packageJson.workspaces) {
                return currentDir;
              }
            }
          }
        } catch (e) {
        }
      }
      const parentDir = path2.dirname(currentDir);
      if (parentDir === currentDir) {
        return null;
      }
      currentDir = parentDir;
      levels++;
    }
    return null;
  }
  async getPathInfo() {
    const monorepoRoot = this.findMonorepoRoot(process.cwd());
    const projectRootForPaths = monorepoRoot || process.cwd();
    const elizaDir = path2.join(projectRootForPaths, ".eliza");
    const envFilePath = resolveEnvFile(process.cwd(), monorepoRoot ?? void 0);
    logger2.debug("[UserEnvironment] Detected monorepo root:", monorepoRoot || "Not in monorepo");
    return {
      elizaDir,
      envFilePath,
      configPath: path2.join(elizaDir, "config.json"),
      pluginsDir: path2.join(elizaDir, "plugins"),
      monorepoRoot,
      packageJsonPath: path2.join(projectRootForPaths, "package.json")
    };
  }
  async getEnvInfo() {
    return { ...process.env };
  }
  async getInfo(directory) {
    const cacheKey = directory || "cwd";
    if (this.cachedInfo[cacheKey]) {
      return this.cachedInfo[cacheKey];
    }
    logger2.debug(`[UserEnvironment] Gathering environment information for directory: ${cacheKey}`);
    const [os2, cli, packageManager, paths, env] = await Promise.all([
      this.getOSInfo(),
      this.getCLIInfo(),
      this.getPackageManagerInfo(),
      this.getPathInfo(),
      this.getEnvInfo()
    ]);
    const info = {
      os: os2,
      cli,
      packageManager,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      paths,
      env
    };
    this.cachedInfo[cacheKey] = info;
    return info;
  }
  /**
   * Clears the cached information
   */
  clearCache() {
    this.cachedInfo = {};
  }
  /**
   * Gets the version of a specified package from monorepo, local dependencies, or npm
   */
  async getPackageVersion(packageName) {
    try {
      const { monorepoRoot } = await this.getPathInfo();
      if (monorepoRoot) {
        const monoRepoPackagePath = path2.join(
          monorepoRoot,
          "packages",
          packageName.replace("@elizaos/", ""),
          "package.json"
        );
        if (existsSync2(monoRepoPackagePath)) {
          const packageJson = JSON.parse(await fs.readFile(monoRepoPackagePath, "utf8"));
          if (packageJson.version) return packageJson.version;
        }
      }
      const cliInfo = await this.getCLIInfo();
      const cliDir = path2.dirname(cliInfo.path);
      const cliPackagePath = path2.join(cliDir, "package.json");
      if (existsSync2(cliPackagePath)) {
        const packageJson = JSON.parse(await fs.readFile(cliPackagePath, "utf8"));
        const versionRange = packageJson.dependencies?.[packageName];
        if (versionRange) {
          const minVer = semver.minVersion(versionRange);
          if (minVer) {
            return minVer.version;
          } else {
            logger2.warn(
              `Could not parse semver range '${versionRange}' for package ${packageName}. Falling back to original string.`
            );
            return versionRange;
          }
        }
      }
      try {
        const { execa: execa9 } = await import("execa");
        const { stdout } = await execa9("npm", ["view", packageName, "version"]);
        if (stdout?.trim()) {
          logger2.info(`Found latest version of ${packageName} from npm: ${stdout.trim()}`);
          return stdout.trim();
        }
      } catch (npmError) {
        logger2.warn(`Could not get latest version from npm: ${npmError}`);
      }
      return "0.25.9";
    } catch (error) {
      logger2.warn(`Error getting package version for ${packageName}: ${error}`);
      return "0.25.9";
    }
  }
  /**
   * Get local packages available in the monorepo
   */
  async getLocalPackages() {
    const { monorepoRoot } = await this.getPathInfo();
    if (!monorepoRoot) return [];
    try {
      const packagesDirEntries = await fs.readdir(path2.join(monorepoRoot, "packages"), {
        withFileTypes: true
      });
      const pluginPackages = packagesDirEntries.filter((entry) => entry.isDirectory() && entry.name.startsWith("plugin-")).map((entry) => `@elizaos/${entry.name}`);
      return pluginPackages;
    } catch (error) {
      logger2.warn(`Error getting local packages: ${error}`);
      return [];
    }
  }
};

// src/utils/directory-detection.ts
function detectDirectoryType(dir) {
  if (!fs2.existsSync(dir)) {
    return {
      type: "non-elizaos-dir",
      hasPackageJson: false,
      hasElizaOSDependencies: false,
      elizaPackageCount: 0
    };
  }
  try {
    fs2.readdirSync(dir);
  } catch (error) {
    return {
      type: "non-elizaos-dir",
      hasPackageJson: false,
      hasElizaOSDependencies: false,
      elizaPackageCount: 0
    };
  }
  const monorepoRoot = UserEnvironment.getInstance().findMonorepoRoot(dir) ?? void 0;
  const packageJsonPath = path3.join(dir, "package.json");
  const hasPackageJson = fs2.existsSync(packageJsonPath);
  if (monorepoRoot) {
    if (path3.resolve(dir) === path3.resolve(monorepoRoot)) {
      return {
        type: "elizaos-monorepo",
        hasPackageJson,
        hasElizaOSDependencies: false,
        elizaPackageCount: 0,
        monorepoRoot
      };
    }
    if (!hasPackageJson) {
      return {
        type: "elizaos-subdir",
        hasPackageJson: false,
        hasElizaOSDependencies: false,
        elizaPackageCount: 0,
        monorepoRoot
      };
    }
  } else if (!hasPackageJson) {
    return {
      type: "non-elizaos-dir",
      hasPackageJson: false,
      hasElizaOSDependencies: false,
      elizaPackageCount: 0,
      monorepoRoot
    };
  }
  let packageJson;
  try {
    const packageJsonContent = fs2.readFileSync(packageJsonPath, "utf8");
    packageJson = JSON.parse(packageJsonContent);
  } catch (error) {
    return {
      type: "non-elizaos-dir",
      hasPackageJson: true,
      hasElizaOSDependencies: false,
      elizaPackageCount: 0,
      monorepoRoot
    };
  }
  const result = {
    type: "non-elizaos-dir",
    // Default, will be updated below
    hasPackageJson: true,
    hasElizaOSDependencies: false,
    elizaPackageCount: 0,
    packageName: packageJson.name,
    monorepoRoot
  };
  const dependencies = { ...packageJson.dependencies, ...packageJson.devDependencies };
  const elizaPackages = Object.keys(dependencies).filter((pkg) => pkg.startsWith("@elizaos/"));
  result.elizaPackageCount = elizaPackages.length;
  result.hasElizaOSDependencies = elizaPackages.length > 0;
  const isPlugin = isElizaOSPlugin(packageJson);
  if (isPlugin) {
    result.type = "elizaos-plugin";
    return result;
  }
  const isProject = isElizaOSProject(packageJson, dir, monorepoRoot);
  if (isProject) {
    result.type = "elizaos-project";
    return result;
  }
  if (monorepoRoot) {
    result.type = "elizaos-subdir";
  } else {
    result.type = "non-elizaos-dir";
  }
  return result;
}
function isElizaOSPlugin(packageJson) {
  if (packageJson.packageType === "plugin") {
    return true;
  }
  const keywords = packageJson.keywords || [];
  if (keywords.includes("plugin")) {
    return true;
  }
  if (packageJson.agentConfig?.pluginType?.includes("plugin")) {
    return true;
  }
  const packageName = packageJson.name || "";
  if (packageName.startsWith("@elizaos/plugin-") || packageName.startsWith("plugin-") || packageName.includes("/plugin-") || packageName.includes("plugin") && packageName.includes("eliza")) {
    return true;
  }
  if (packageJson.main && (packageJson.main.includes("plugin") || packageJson.main === "src/index.ts" || packageJson.main === "dist/index.js")) {
    const allDeps = { ...packageJson.dependencies, ...packageJson.devDependencies };
    const hasElizaCore = Object.keys(allDeps).some((dep) => dep.startsWith("@elizaos/core"));
    if (hasElizaCore && keywords.length > 0) {
      return true;
    }
  }
  return false;
}
function isElizaOSProject(packageJson, dir, monorepoRoot) {
  if (packageJson.packageType === "project") {
    return true;
  }
  const keywords = packageJson.keywords || [];
  if (keywords.includes("project")) {
    return true;
  }
  if (packageJson.agentConfig?.pluginType?.includes("project")) {
    return true;
  }
  const packageName = packageJson.name || "";
  if (packageName.startsWith("@elizaos/project-") || packageName.startsWith("project-") || packageName.includes("/project-") || packageName.includes("project") && packageName.includes("eliza")) {
    return true;
  }
  if (!monorepoRoot) {
    const srcIndexPath = path3.join(dir, "src", "index.ts");
    if (fs2.existsSync(srcIndexPath)) {
      try {
        const indexContent = fs2.readFileSync(srcIndexPath, "utf8");
        if (indexContent.includes("export const project") || indexContent.includes("Project") || indexContent.includes("agents")) {
          return true;
        }
      } catch {
      }
    }
    const characterFiles = ["character.json", "characters.json", "characters"];
    for (const file of characterFiles) {
      if (fs2.existsSync(path3.join(dir, file))) {
        return true;
      }
    }
    const projectDirs = ["characters", "agents", ".eliza"];
    for (const dirName of projectDirs) {
      if (fs2.existsSync(path3.join(dir, dirName))) {
        const stat = fs2.statSync(path3.join(dir, dirName));
        if (stat.isDirectory()) {
          return true;
        }
      }
    }
    const allDeps = { ...packageJson.dependencies, ...packageJson.devDependencies };
    const hasElizaCore = Object.keys(allDeps).some((dep) => dep.startsWith("@elizaos/core"));
    const hasMultipleElizaPackages = Object.keys(allDeps).filter((dep) => dep.startsWith("@elizaos/")).length >= 2;
    if (hasElizaCore && hasMultipleElizaPackages) {
      return true;
    }
  }
  return false;
}
function isValidForUpdates(info) {
  return info.type === "elizaos-project" || info.type === "elizaos-plugin" || info.type === "elizaos-monorepo" || info.type === "elizaos-subdir";
}

// src/utils/build-project.ts
async function buildProject(cwd = process.cwd(), isPlugin = false) {
  if (process.env.ELIZA_TEST_MODE) {
    console.info("Skipping build in test mode");
    return;
  }
  logger3.info(`Building ${isPlugin ? "plugin" : "project"} in ${cwd}...`);
  if (!fs3.existsSync(cwd)) {
    throw new Error(`Project directory ${cwd} does not exist.`);
  }
  const dirInfo = detectDirectoryType(cwd);
  if (!dirInfo.hasPackageJson) {
    logger3.warn(`package.json not found in ${cwd}. Cannot determine build method.`);
    throw new Error(`Project directory ${cwd} does not have package.json.`);
  }
  const packageJsonPath = path4.join(cwd, "package.json");
  const distPath = path4.join(cwd, "dist");
  if (fs3.existsSync(distPath)) {
    await fs3.promises.rm(distPath, { recursive: true, force: true });
    logger3.debug(`Cleaned previous build artifacts from ${distPath}`);
  }
  const directoryInfo = detectDirectoryType(cwd);
  if (directoryInfo.monorepoRoot) {
    logger3.debug("Detected monorepo structure, skipping install");
  }
  try {
    const packageJson = JSON.parse(fs3.readFileSync(packageJsonPath, "utf8"));
    if (packageJson.scripts?.build) {
      logger3.debug("Using build script from package.json with bun");
      try {
        logger3.debug("Building with bun...");
        await runBunCommand(["run", "build"], cwd);
        logger3.info(`Build completed successfully`);
        return;
      } catch (buildError) {
        logger3.debug(`Bun build failed: ${buildError}`);
        throw new Error(`Failed to build using bun: ${buildError}`);
      }
    }
    logger3.warn(`No build script found in ${packageJsonPath}. Attempting common build commands.`);
    const tsconfigPath = path4.join(cwd, "tsconfig.json");
    if (fs3.existsSync(tsconfigPath)) {
      try {
        logger3.debug("Found tsconfig.json, attempting to build with bunx tsc...");
        await execa2("bunx", ["tsc", "--build"], { cwd, stdio: "inherit" });
        logger3.info(`Build completed successfully`);
        return;
      } catch (tscError) {
        logger3.debug(`bunx tsc build failed: ${tscError}`);
      }
    }
    throw new Error("Could not determine how to build the project");
  } catch (error) {
    logger3.error(`Failed to build ${isPlugin ? "plugin" : "project"}: ${error}`);
    throw error;
  }
}

// src/utils/cli-bun-migration.ts
import { logger as logger4 } from "@elizaos/core";
import { execa as execa3 } from "execa";
async function isBunAvailable() {
  try {
    await execa3("bun", ["--version"], { stdio: "ignore" });
    return true;
  } catch (error) {
    return false;
  }
}
async function isCliInstalledViaNpm() {
  try {
    const { stdout } = await execa3("npm", ["list", "-g", "@elizaos/cli", "--depth=0"], {
      stdio: "pipe"
    });
    return stdout.includes("@elizaos/cli");
  } catch (error) {
    try {
      const { stdout: whichOutput } = await execa3("which", ["elizaos"], { stdio: "pipe" });
      return whichOutput.includes("node_modules") || whichOutput.includes(".nvm");
    } catch {
      return false;
    }
  }
}
async function removeNpmInstallation() {
  logger4.info("Removing npm installation of @elizaos/cli...");
  await execa3("npm", ["uninstall", "-g", "@elizaos/cli"], { stdio: "inherit" });
}
async function installCliWithBun(version) {
  logger4.info("Installing CLI with bun...");
  await execa3("bun", ["add", "-g", `@elizaos/cli@${version}`], { stdio: "inherit" });
}
async function verifyCliInstallation(expectedVersion) {
  try {
    const { stdout } = await execa3("elizaos", ["-v"], { stdio: "pipe" });
    const output = stdout.trim();
    const versionMatch = output.match(/(\d+\.\d+\.\d+(?:-[a-zA-Z0-9.-]+)?)/);
    if (!versionMatch) {
      return false;
    }
    const actualVersion = versionMatch[1];
    return actualVersion === expectedVersion || expectedVersion.includes(actualVersion) || actualVersion.includes(expectedVersion);
  } catch {
    return false;
  }
}
async function migrateCliToBun(targetVersion) {
  if (!await isBunAvailable()) {
    throw new Error(
      "Bun is not available. Please install bun first: https://bun.sh/docs/installation"
    );
  }
  logger4.info("Starting atomic CLI migration from npm to bun...");
  try {
    await installCliWithBun(targetVersion);
    logger4.info("Verifying bun installation...");
    if (!await verifyCliInstallation(targetVersion)) {
      throw new Error("Bun installation verification failed");
    }
    logger4.info("Bun installation successful, removing npm installation...");
    await removeNpmInstallation();
    logger4.info("\u2705 CLI migration completed successfully! You may need to restart your terminal.");
  } catch (error) {
    logger4.error(
      `\u274C CLI migration failed: ${error instanceof Error ? error.message : String(error)}`
    );
    logger4.error("Your original npm installation is still intact.");
    try {
      logger4.info("Cleaning up failed bun installation...");
      await execa3("bun", ["remove", "-g", "@elizaos/cli"], { stdio: "ignore" });
    } catch {
    }
    throw error;
  }
}

// src/utils/cli-prompts.ts
import * as clack from "@clack/prompts";
import { logger as logger5 } from "@elizaos/core";
var NAV_BACK = "__back__";
var NAV_NEXT = "__next__";
async function promptWithNav(label, initial = "", validate) {
  const msg = `${label}${initial ? ` (current: ${initial})` : ""}`;
  const input = await clack.text({
    message: msg,
    placeholder: initial,
    defaultValue: initial,
    validate: validate ? (val) => {
      const result = validate(val);
      return typeof result === "string" ? result : void 0;
    } : void 0
  });
  if (clack.isCancel(input)) {
    clack.cancel("Operation cancelled.");
    process.exit(0);
  }
  const trimmedInput = input.trim();
  if (trimmedInput.toLowerCase() === "cancel") return "cancel";
  if (trimmedInput.toLowerCase() === "back") return NAV_BACK;
  if (trimmedInput.toLowerCase() === "quit" || trimmedInput.toLowerCase() === "exit") {
    logger5.info("Exiting...");
    process.exit(0);
  }
  if (trimmedInput === "" && initial) return initial;
  if (trimmedInput === "" || trimmedInput.toLowerCase() === "next") return NAV_NEXT;
  return trimmedInput;
}
async function promptForMultipleItems(fieldName, initial = []) {
  const items = [...initial];
  logger5.info(`
${fieldName}`);
  if (initial.length > 0) {
    logger5.info("Current values:");
    initial.forEach((item, i) => logger5.info(`  ${i + 1}. ${item}`));
    logger5.info("\nPress Enter to keep existing values, or start typing new ones:");
  }
  while (true) {
    const val = await promptWithNav(`> ${fieldName}:`);
    if (val === NAV_NEXT) break;
    if (val === NAV_BACK) {
      if (items.length === initial.length) return initial;
      break;
    }
    if (val === "cancel") return initial;
    items.push(val);
  }
  return items;
}
async function confirmAction(message) {
  const response = await clack.confirm({
    message,
    initialValue: false
  });
  if (clack.isCancel(response)) {
    clack.cancel("Operation cancelled.");
    process.exit(0);
  }
  return Boolean(response);
}

// src/utils/config-manager.ts
import path6 from "path";
import { promises as fs5 } from "fs";
import { logger as logger7 } from "@elizaos/core";

// src/utils/env-prompt.ts
import * as clack2 from "@clack/prompts";
import colors from "yoctocolors";
import { promises as fs4 } from "fs";
import path5 from "path";
import { logger as logger6 } from "@elizaos/core";
var ENV_VAR_CONFIGS = {
  openai: [
    {
      name: "OpenAI API Key",
      key: "OPENAI_API_KEY",
      required: true,
      description: "Required for the OpenAI plugin to generate text and embeddings.",
      url: "https://platform.openai.com/api-keys",
      secret: true
    }
  ],
  anthropic: [
    {
      name: "Anthropic API Key",
      key: "ANTHROPIC_API_KEY",
      required: true,
      description: "Required for the Anthropic plugin to use Claude models.",
      url: "https://console.anthropic.com/settings/keys",
      secret: true
    }
  ],
  discord: [
    {
      name: "Discord API Token",
      key: "DISCORD_API_TOKEN",
      required: false,
      description: "The bot token for your Discord application. This enables your agent to connect to Discord and interact with users there.",
      url: "https://discord.com/developers/applications",
      secret: true
    },
    {
      name: "Discord Application ID",
      key: "DISCORD_APPLICATION_ID",
      required: false,
      description: "The application ID for your Discord bot. Required together with the API token to enable Discord integration.",
      url: "https://discord.com/developers/applications",
      secret: false
    }
  ],
  twitter: [
    {
      name: "Twitter API Key",
      key: "TWITTER_API_KEY",
      required: false,
      description: "API Key for Twitter integration. Needed to connect your agent to Twitter.",
      url: "https://developer.twitter.com/en/portal/dashboard",
      secret: true
    },
    {
      name: "Twitter API Secret",
      key: "TWITTER_API_SECRET",
      required: false,
      description: "API Secret for Twitter integration.",
      url: "https://developer.twitter.com/en/portal/dashboard",
      secret: true
    },
    {
      name: "Twitter Access Token",
      key: "TWITTER_ACCESS_TOKEN",
      required: false,
      description: "Access Token for Twitter integration.",
      url: "https://developer.twitter.com/en/portal/dashboard",
      secret: true
    },
    {
      name: "Twitter Access Token Secret",
      key: "TWITTER_ACCESS_TOKEN_SECRET",
      required: false,
      description: "Access Token Secret for Twitter integration.",
      url: "https://developer.twitter.com/en/portal/dashboard",
      secret: true
    }
  ],
  telegram: [
    {
      name: "Telegram Bot Token",
      key: "TELEGRAM_BOT_TOKEN",
      required: false,
      description: "Bot Token for Telegram integration. Needed to connect your agent to Telegram.",
      url: "https://core.telegram.org/bots#how-do-i-create-a-bot",
      secret: true
    }
  ],
  pglite: [
    {
      name: "Database Directory",
      key: "PGLITE_DATA_DIR",
      required: false,
      description: "Directory where PGLite will store database files.",
      url: "",
      secret: false
    }
  ],
  postgresql: [
    {
      name: "PostgreSQL URL",
      key: "POSTGRES_URL",
      required: false,
      description: "URL for connecting to your PostgreSQL database.",
      url: "https://neon.tech/docs/connect/connect-from-any-app",
      secret: false
    }
  ]
};
async function getEnvFilePath() {
  const envInfo = await UserEnvironment.getInstanceInfo();
  return envInfo.paths.envFilePath;
}
async function readEnvFile() {
  const envPath = await getEnvFilePath();
  const result = {};
  try {
    if (await fs4.access(envPath).then(() => true).catch(() => false)) {
      const content = await fs4.readFile(envPath, "utf8");
      const lines = content.split("\n");
      for (const line of lines) {
        const trimmedLine = line.trim();
        if (trimmedLine && !trimmedLine.startsWith("#")) {
          const separatorIndex = trimmedLine.indexOf("=");
          if (separatorIndex > 0) {
            const key = trimmedLine.substring(0, separatorIndex).trim();
            const value = trimmedLine.substring(separatorIndex + 1).trim();
            result[key] = value;
          }
        }
      }
    }
  } catch (error) {
    logger6.error(`Error reading environment file: ${error}`);
  }
  return result;
}
async function writeEnvFile(envVars) {
  try {
    const envPath = await getEnvFilePath();
    const elizaDir = path5.dirname(envPath);
    if (!await fs4.access(elizaDir).then(() => true).catch(() => false)) {
      await fs4.mkdir(elizaDir, { recursive: true });
    }
    let content = "";
    for (const [key, value] of Object.entries(envVars)) {
      content += `${key}=${value}
`;
    }
    await fs4.writeFile(envPath, content, "utf8");
    logger6.info(`Environment variables saved to ${envPath}`);
  } catch (error) {
    logger6.error(`Error writing environment file: ${error}`);
  }
}
async function promptForEnvVar(config) {
  const existingValue = process.env[config.key];
  if (existingValue && existingValue.trim() !== "") {
    return existingValue;
  }
  console.log(
    colors.magenta(
      `
${config.name} ${config.required ? "(Required)" : "(Optional - press Enter to skip)"}`
    )
  );
  console.log(colors.white(config.description));
  if (config.url) {
    console.log(colors.blue(`Get it here: ${config.url}`));
  }
  const value = await (config.secret ? clack2.password({
    message: `Enter your ${config.name}:`,
    validate: (input) => {
      if (config.required && (!input || input.trim() === "")) {
        return "This field is required";
      }
      return void 0;
    }
  }) : clack2.text({
    message: `Enter your ${config.name}:`,
    validate: (input) => {
      if (config.required && (!input || input.trim() === "")) {
        return "This field is required";
      }
      return void 0;
    }
  }));
  if (clack2.isCancel(value)) {
    clack2.cancel("Operation cancelled.");
    process.exit(0);
  }
  if (!config.required && (!value || value.trim() === "")) {
    return "";
  }
  if (config.key === "PGLITE_DATA_DIR" && value && value.startsWith("~")) {
    return value.replace(/^~/, process.cwd());
  }
  return value;
}
async function promptForEnvVars(pluginName) {
  const envVarConfigs = ENV_VAR_CONFIGS[pluginName.toLowerCase()];
  if (!envVarConfigs) {
    return {};
  }
  if (pluginName.toLowerCase() === "discord") {
    console.log(colors.blue("\n=== Discord Integration (Optional) ==="));
    console.log(
      colors.white(
        "Setting up Discord integration will allow your agent to interact with Discord users."
      )
    );
    console.log(
      colors.white("You can press Enter to skip these if you don't want to use Discord.")
    );
  } else if (pluginName.toLowerCase() === "twitter") {
    console.log(colors.blue("\n=== Twitter Integration (Optional) ==="));
    console.log(
      colors.white(
        "Setting up Twitter integration will allow your agent to post and interact on Twitter."
      )
    );
    console.log(
      colors.white("You can press Enter to skip these if you don't want to use Twitter.")
    );
  } else if (pluginName.toLowerCase() === "telegram") {
    console.log(colors.blue("\n=== Telegram Integration (Optional) ==="));
    console.log(
      colors.white(
        "Setting up Telegram integration will allow your agent to interact in Telegram chats."
      )
    );
    console.log(
      colors.white("You can press Enter to skip these if you don't want to use Telegram.")
    );
  }
  const envVars = await readEnvFile();
  const result = {};
  let changes = false;
  for (const config of envVarConfigs) {
    if (envVars[config.key] && envVars[config.key] !== "dummy_key" && envVars[config.key] !== "invalid_token_for_testing") {
      continue;
    }
    await new Promise((resolve2) => setTimeout(resolve2, 100));
    const value = await promptForEnvVar(config);
    if (value !== null) {
      result[config.key] = value;
      envVars[config.key] = value;
      process.env[config.key] = value;
    }
    changes = true;
  }
  if (changes) {
    writeEnvFile(envVars);
  }
  return result;
}
async function validateEnvVars(pluginName) {
  const envVarConfigs = ENV_VAR_CONFIGS[pluginName.toLowerCase()];
  if (!envVarConfigs) {
    return true;
  }
  const envVars = await readEnvFile();
  for (const config of envVarConfigs) {
    if (config.required && (!envVars[config.key] || envVars[config.key] === "dummy_key")) {
      return false;
    }
  }
  return true;
}
async function getMissingEnvVars(pluginName) {
  const envVarConfigs = ENV_VAR_CONFIGS[pluginName.toLowerCase()];
  if (!envVarConfigs) {
    return [];
  }
  const envVars = await readEnvFile();
  const missing = [];
  for (const config of envVarConfigs) {
    if (config.required && (!envVars[config.key] || envVars[config.key] === "dummy_key")) {
      missing.push(config.key);
    }
  }
  return missing;
}
async function validatePluginEnvVars(pluginName) {
  const envVars = await readEnvFile();
  switch (pluginName.toLowerCase()) {
    case "discord":
      if (envVars.DISCORD_API_TOKEN && envVars.DISCORD_API_TOKEN.trim() !== "" && (!envVars.DISCORD_APPLICATION_ID || envVars.DISCORD_APPLICATION_ID.trim() === "")) {
        return {
          valid: false,
          message: "Discord Application ID is required when using a Discord API Token"
        };
      }
      if (envVars.DISCORD_API_TOKEN && envVars.DISCORD_API_TOKEN.trim() !== "" && envVars.DISCORD_APPLICATION_ID && envVars.DISCORD_APPLICATION_ID.trim() !== "") {
        return {
          valid: true,
          message: "Discord integration is properly configured."
        };
      }
      if ((!envVars.DISCORD_API_TOKEN || envVars.DISCORD_API_TOKEN.trim() === "") && (!envVars.DISCORD_APPLICATION_ID || envVars.DISCORD_APPLICATION_ID.trim() === "")) {
        return {
          valid: true,
          message: "Discord integration is not configured (optional)."
        };
      }
      return {
        valid: false,
        message: "Discord configuration is incomplete. Please provide both API Token and Application ID."
      };
    case "twitter": {
      const twitterKeys = [
        "TWITTER_API_KEY",
        "TWITTER_API_SECRET",
        "TWITTER_ACCESS_TOKEN",
        "TWITTER_ACCESS_TOKEN_SECRET"
      ];
      const providedKeys = twitterKeys.filter((key) => envVars[key] && envVars[key].trim() !== "");
      if (providedKeys.length > 0 && providedKeys.length < twitterKeys.length) {
        return {
          valid: false,
          message: `Twitter configuration is incomplete. Missing: ${twitterKeys.filter((key) => !providedKeys.includes(key)).join(", ")}`
        };
      }
      if (providedKeys.length === twitterKeys.length) {
        return {
          valid: true,
          message: "Twitter configuration is valid"
        };
      }
      return {
        valid: true,
        message: "Twitter integration is not configured (optional)."
      };
    }
    case "telegram":
      if (envVars.TELEGRAM_BOT_TOKEN && envVars.TELEGRAM_BOT_TOKEN.trim() !== "") {
        return {
          valid: true,
          message: "Telegram configuration is valid"
        };
      }
      return {
        valid: false,
        message: "Telegram Bot Token is required for Telegram integration"
      };
    case "openai":
      if (envVars.OPENAI_API_KEY && envVars.OPENAI_API_KEY.trim() !== "") {
        return {
          valid: true,
          message: "OpenAI configuration is valid"
        };
      }
      return {
        valid: false,
        message: "OpenAI API Key is required for OpenAI integration"
      };
    case "anthropic":
      if (envVars.ANTHROPIC_API_KEY && envVars.ANTHROPIC_API_KEY.trim() !== "") {
        return {
          valid: true,
          message: "Anthropic configuration is valid"
        };
      }
      return {
        valid: false,
        message: "Anthropic API Key is required for Anthropic integration"
      };
    case "postgres":
      if (envVars.POSTGRES_URL && envVars.POSTGRES_URL.trim() !== "") {
        return {
          valid: true,
          message: "PostgreSQL configuration is valid"
        };
      }
      return {
        valid: false,
        message: "PostgreSQL URL is required for PostgreSQL integration"
      };
    default:
      return {
        valid: true,
        message: `No specific validation rules for ${pluginName}`
      };
  }
}

// src/utils/config-manager.ts
async function getConfigFilePath() {
  const envInfo = await UserEnvironment.getInstanceInfo();
  return envInfo.paths.configPath;
}
async function fileExists(p) {
  try {
    await fs5.access(p);
    return true;
  } catch {
    return false;
  }
}
async function loadConfig() {
  try {
    const configPath = await getConfigFilePath();
    if (!await fileExists(configPath)) {
      return {
        lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
        isDefault: true
        // Mark as default config
      };
    }
    const content = await fs5.readFile(configPath, "utf8");
    return JSON.parse(content);
  } catch (error) {
    logger7.warn(`Error loading configuration: ${error}`);
    return {
      lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
      isDefault: true
      // Mark as default config
    };
  }
}
async function saveConfig(config) {
  try {
    const configPath = await getConfigFilePath();
    const elizaDir = path6.dirname(configPath);
    if (!await fileExists(elizaDir)) {
      await fs5.mkdir(elizaDir, { recursive: true });
    }
    config.lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
    await fs5.writeFile(configPath, JSON.stringify(config, null, 2), "utf8");
    logger7.info(`Configuration saved to ${configPath}`);
  } catch (error) {
    logger7.error(`Error saving configuration: ${error}`);
  }
}
async function checkPluginRequirements(pluginName) {
  return validatePluginEnvVars(pluginName);
}
async function getPluginStatus() {
  const configPath = await getConfigFilePath();
  if (!await fileExists(configPath)) {
    return {};
  }
  try {
    const configContent = await fs5.readFile(configPath, "utf-8");
    const config = JSON.parse(configContent);
    const status = {};
    for (const plugin of Object.keys(config.plugins ?? {})) {
      const check = await validatePluginEnvVars(plugin);
      status[plugin] = check.valid;
    }
    return status;
  } catch (error) {
    logger7.error(`Error reading config file: ${error}`);
    return {};
  }
}

// src/utils/copy-template.ts
import { existsSync as existsSync5 } from "fs";
import { promises as fs6 } from "fs";
import path7 from "path";
import { fileURLToPath as fileURLToPath2 } from "url";
import { logger as logger8 } from "@elizaos/core";
var __filename = fileURLToPath2(import.meta.url);
var __dirname = path7.dirname(__filename);
async function copyDir(src, dest, exclude = []) {
  const resolvedSrc = path7.resolve(src);
  const resolvedDest = path7.resolve(dest);
  await fs6.mkdir(resolvedDest, { recursive: true });
  const entries = await fs6.readdir(resolvedSrc, { withFileTypes: true });
  const files = [];
  const directories = [];
  for (const entry of entries) {
    if (exclude.includes(entry.name)) {
      continue;
    }
    if (entry.name === "node_modules" || entry.name === ".git" || entry.name === "cache" || entry.name === "data" || entry.name === "generatedImages" || entry.name === ".turbo") {
      continue;
    }
    if (entry.isDirectory()) {
      directories.push(entry);
    } else {
      files.push(entry);
    }
  }
  const MAX_CONCURRENT_FILES = 10;
  const filePromises = [];
  for (let i = 0; i < files.length; i += MAX_CONCURRENT_FILES) {
    const batch = files.slice(i, i + MAX_CONCURRENT_FILES);
    const batchPromises = batch.map(async (entry) => {
      const srcPath = path7.join(resolvedSrc, entry.name);
      const destPath = path7.join(resolvedDest, entry.name);
      await fs6.copyFile(srcPath, destPath);
    });
    filePromises.push(...batchPromises);
  }
  await Promise.all(filePromises);
  for (const entry of directories) {
    const srcPath = path7.join(resolvedSrc, entry.name);
    const destPath = path7.join(resolvedDest, entry.name);
    await copyDir(srcPath, destPath, exclude);
  }
}
function getPackageName(templateType) {
  switch (templateType) {
    case "project-tee-starter":
      return "project-tee-starter";
    case "plugin":
      return "plugin-starter";
    case "project":
    case "project-starter":
    default:
      return "project-starter";
  }
}
async function copyTemplate(templateType, targetDir) {
  const packageName = getPackageName(templateType);
  const possibleTemplatePaths = [
    // 1. Direct path from source directory (for tests and development)
    path7.resolve(__dirname, "../../templates", packageName),
    // 2. Production: templates bundled with the CLI dist
    path7.resolve(
      path7.dirname(__require.resolve("@elizaos/cli/package.json")),
      "dist",
      "templates",
      packageName
    ),
    // 3. Development/Test: templates in the CLI package root
    path7.resolve(
      path7.dirname(__require.resolve("@elizaos/cli/package.json")),
      "templates",
      packageName
    ),
    // 4. Fallback: relative to current module (for built dist)
    path7.resolve(__dirname, "..", "templates", packageName),
    // 5. Additional fallback: relative to dist directory
    path7.resolve(__dirname, "..", "..", "templates", packageName)
  ];
  let templateDir = null;
  for (const possiblePath of possibleTemplatePaths) {
    if (existsSync5(possiblePath)) {
      templateDir = possiblePath;
      break;
    }
  }
  if (!templateDir) {
    throw new Error(
      `Template '${packageName}' not found. Searched in:
${possibleTemplatePaths.join("\n")}`
    );
  }
  logger8.debug(`Copying ${templateType} template from ${templateDir} to ${targetDir}`);
  await copyDir(templateDir, targetDir);
  if (templateType === "plugin") {
    const pluginNameFromPath = path7.basename(targetDir);
    await replacePluginNameInFiles(targetDir, pluginNameFromPath);
  }
  const packageJsonPath = path7.join(targetDir, "package.json");
  try {
    const cliPackageJsonPath = path7.resolve(
      path7.dirname(__require.resolve("@elizaos/cli/package.json")),
      "package.json"
    );
    const cliPackageJson = JSON.parse(await fs6.readFile(cliPackageJsonPath, "utf8"));
    const cliPackageVersion = cliPackageJson.version;
    const packageJson = JSON.parse(await fs6.readFile(packageJsonPath, "utf8"));
    if (packageJson.private) {
      delete packageJson.private;
      logger8.debug("Removed private field from template package.json");
    }
    if (packageJson.dependencies) {
      for (const depName of Object.keys(packageJson.dependencies)) {
        if (depName.startsWith("@elizaos/")) {
          logger8.info(`Setting ${depName} to use version ${cliPackageVersion}`);
          packageJson.dependencies[depName] = "latest";
        }
      }
    }
    if (packageJson.devDependencies) {
      for (const depName of Object.keys(packageJson.devDependencies)) {
        if (depName.startsWith("@elizaos/")) {
          logger8.info(`Setting dev dependency ${depName} to use version ${cliPackageVersion}`);
          packageJson.devDependencies[depName] = "latest";
        }
      }
    }
    const projectNameFromPath = path7.basename(targetDir);
    if (packageJson.name !== projectNameFromPath) {
      packageJson.name = projectNameFromPath;
      logger8.info(`Setting package name to ${projectNameFromPath}`);
    }
    await fs6.writeFile(packageJsonPath, JSON.stringify(packageJson, null, 2));
    logger8.debug("Updated package.json with latest dependency versions");
  } catch (error) {
    logger8.error(`Error updating package.json: ${error}`);
  }
  logger8.debug(`${templateType} template copied successfully`);
}
async function replacePluginNameInFiles(targetDir, pluginName) {
  const filesToProcess = [
    "src/index.ts",
    "__tests__/plugin.test.ts",
    "e2e/starter-plugin.test.ts",
    "README.md"
    // package.json name is handled by the publish command
  ];
  const promises2 = filesToProcess.map(async (filePath) => {
    const fullPath = path7.join(targetDir, filePath);
    try {
      if (await fs6.access(fullPath).then(() => true).catch(() => false)) {
        let content = await fs6.readFile(fullPath, "utf8");
        content = content.replace(/plugin-starter/g, pluginName);
        await fs6.writeFile(fullPath, content, "utf8");
        logger8.debug(`Updated plugin name in ${filePath}`);
      }
    } catch (error) {
      logger8.warn(
        `Could not update ${filePath}: ${error instanceof Error ? error.message : String(error)}`
      );
    }
  });
  await Promise.all(promises2);
}
async function copyClientDist() {
  logger8.debug("Copying client dist files to CLI package");
  const srcClientDist = path7.resolve(process.cwd(), "../client/dist");
  const destClientDist = path7.resolve(process.cwd(), "./dist");
  const indexSrc = path7.join(srcClientDist, "index.html");
  const indexDest = path7.join(destClientDist, "index.html");
  await fs6.mkdir(destClientDist, { recursive: true });
  let retries = 0;
  const maxRetries = 10;
  const retryDelay = 1e3;
  while (retries < maxRetries) {
    if (existsSync5(indexSrc)) {
      break;
    }
    logger8.info(`Waiting for client index.html (attempt ${retries + 1}/${maxRetries})\u2026`);
    await new Promise((r) => setTimeout(r, retryDelay));
    retries++;
  }
  if (!existsSync5(indexSrc)) {
    logger8.error(`index.html not found at ${indexSrc} after ${maxRetries} attempts`);
    return;
  }
  await copyDir(srcClientDist, destClientDist);
  if (!existsSync5(indexDest)) {
    logger8.error(`index.html missing in CLI dist at ${indexDest}`);
    return;
  }
  logger8.success("Client dist files copied successfully");
}

// src/utils/display-banner.ts
import { existsSync as existsSync6, readFileSync as readFileSync4 } from "fs";
import path8, { dirname } from "path";
import { fileURLToPath as fileURLToPath3 } from "url";
import { execa as execa4 } from "execa";
function getVersion() {
  const __filename2 = fileURLToPath3(import.meta.url);
  const __dirname2 = dirname(__filename2);
  const packageJsonPath = path8.resolve(__dirname2, "../package.json");
  let version = "0.0.0";
  if (!existsSync6(packageJsonPath)) {
    console.error(`Warning: package.json not found at ${packageJsonPath}`);
  } else {
    try {
      const packageJson = JSON.parse(readFileSync4(packageJsonPath, "utf-8"));
      version = packageJson.version || "0.0.0";
    } catch (error) {
      console.error(`Error reading or parsing package.json at ${packageJsonPath}:`, error);
    }
  }
  return version;
}
function getCliInstallTag() {
  const version = getVersion();
  if (version.includes("-alpha")) {
    return "alpha";
  } else if (version.includes("beta")) {
    return "beta";
  }
  return "";
}
function isUtf8Locale() {
  for (const key of ["LC_ALL", "LC_CTYPE", "LANG", "LANGUAGE"]) {
    const v = process.env[key];
    if (typeof v === "string" && /UTF-?8/i.test(v)) {
      return true;
    }
  }
  return false;
}
var versionCheckCache = null;
var CACHE_DURATION = 10 * 60 * 1e3;
async function getLatestCliVersion(currentVersion) {
  try {
    if (versionCheckCache && Date.now() - versionCheckCache.timestamp < CACHE_DURATION) {
      return versionCheckCache.latestVersion;
    }
    const { stdout } = await execa4("npm", ["view", "@elizaos/cli", "time", "--json"]);
    const timeData = JSON.parse(stdout);
    delete timeData.created;
    delete timeData.modified;
    let latestVersion = "";
    let latestDate = /* @__PURE__ */ new Date(0);
    for (const [version, dateString] of Object.entries(timeData)) {
      const publishDate = new Date(dateString);
      if (publishDate > latestDate) {
        latestDate = publishDate;
        latestVersion = version;
      }
    }
    const result = latestVersion && latestVersion !== currentVersion ? latestVersion : null;
    versionCheckCache = {
      latestVersion: result,
      timestamp: Date.now()
    };
    return result;
  } catch {
    return null;
  }
}
function showUpdateNotification(currentVersion, latestVersion) {
  const blue = "\x1B[38;5;27m";
  const orange = "\x1B[38;5;208m";
  const green = "\x1B[38;5;46m";
  const reset = "\x1B[0m";
  const bold = "\x1B[1m";
  const width = 68;
  const border = `${blue}${"\u2500".repeat(width)}${reset}`;
  console.log("");
  console.log(border);
  console.log(
    `${blue}\u2502${orange} ${bold}Update available:${reset}${orange} ${currentVersion} \u2192 ${green}${bold}${latestVersion}${reset}${orange}${" ".repeat(width - 2 - ` Update available: ${currentVersion} \u2192 ${latestVersion}`.length)}${blue}\u2502${reset}`
  );
  console.log(
    `${blue}\u2502${orange} Run ${green}${bold}bun i -g @elizaos/cli@latest${reset}${orange} to get the latest features${" ".repeat(width - 2 - ` Run bun i -g @elizaos/cli@latest to get the latest features`.length)}${blue}\u2502${reset}`
  );
  console.log(border);
  console.log("");
}
async function checkAndShowUpdateNotification(currentVersion) {
  try {
    const latestVersion = await getLatestCliVersion(currentVersion);
    if (latestVersion) {
      showUpdateNotification(currentVersion, latestVersion);
      return true;
    }
    return false;
  } catch {
    return false;
  }
}
async function displayBanner(skipUpdateCheck = false) {
  if (!isUtf8Locale()) {
    return;
  }
  const b = "\x1B[38;5;27m";
  const lightblue = "\x1B[38;5;51m";
  const w = "\x1B[38;5;255m";
  const r = "\x1B[0m";
  const orange = "\x1B[38;5;208m";
  let versionColor = lightblue;
  const version = getVersion();
  if (version?.includes("alpha")) {
    versionColor = orange;
  }
  const banners = [
    //     // Banner 2
    //     `
    // ${b}          ###                                  ${w}  # ###       #######  ${r}
    // ${b}         ###    #                            / ${w} /###     /       ###  ${r}
    // ${b}          ##   ###                          /  ${w}/  ###   /         ##  ${r}
    // ${b}          ##    #                          / ${w} ##   ###  ##        #   ${r}
    // ${b}          ##                              /  ${w}###    ###  ###          ${r}
    // ${b}   /##    ##  ###    ######      /###    ${w}##   ##     ## ## ###        ${r}
    // ${b}  / ###   ##   ###  /#######    / ###  / ${w}##   ##     ##  ### ###      ${r}
    // ${b} /   ###  ##    ## /      ##   /   ###/  ${w}##   ##     ##    ### ###    ${r}
    // ${b}##    ### ##    ##        /   ##    ##   ${w}##   ##     ##      ### /##  ${r}
    // ${b}########  ##    ##       /    ##    ##   ${w}##   ##     ##        #/ /## ${r}
    // ${b}#######   ##    ##      ###   ##    ##   ${w} ##  ##     ##         #/ ## ${r}
    // ${b}##        ##    ##       ###  ##    ##   ${w}  ## #      /           # /  ${r}
    // ${b}####    / ##    ##        ### ##    /#   ${w}   ###     /  /##        /   ${r}
    // ${b} ######/  ### / ### /      ##  ####/ ##  ${w}    ######/  /  ########/    ${r}
    // ${b}  #####    ##/   ##/       ##   ###   ## ${w}      ###   /     #####      ${r}
    // ${b}                           /             ${w}            |                ${r}
    // ${b}                          /              ${w}             \)              ${r}
    // ${b}                         /               ${w}                             ${r}
    // ${b}                        /                ${w}                             ${r}
    // `,
    //     // Banner 3
    //     `
    // ${b}      :::::::::::::      ::::::::::::::::::::    ::: ${w}    ::::::::  :::::::: ${r}
    // ${b}     :+:       :+:          :+:         :+:   :+: :+:${w}  :+:    :+::+:    :+: ${r}
    // ${b}    +:+       +:+          +:+        +:+   +:+   +:+${w} +:+    +:++:+         ${r}
    // ${b}   +#++:++#  +#+          +#+       +#+   +#++:++#++:${w}+#+    +:++#++:++#++   ${r}
    // ${b}  +#+       +#+          +#+      +#+    +#+     +#+${w}+#+    +#+       +#+    ${r}
    // ${b} #+#       #+#          #+#     #+#     #+#     #+##${w}+#    #+##+#    #+#     ${r}
    // ${b}##########################################     #### ${w}#######  ########       ${r}`,
    `
${b}\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28D0\u28FF\u28FF\u28B0\u2840\u2800\u2800\u2800${w} \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800${w}\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800${r}
${b}\u2800\u2800\u2800\u2800\u2800\u2880\u28F4\u2824\u283E\u281B\u281B\u28FF\u28F6\u28C7\u2800\u2800\u2846${w} \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800${w}\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800${r}
${b}\u28B0\u28CB\u2873\u2844\u2800\u28A8\u28ED\u2840\u2800\u2864\u2800\u28C0\u28DD\u28BF\u28F6\u28FF\u2845${w} \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800${w}\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800${r}
${b}\u28B8\u28EF\u2800\u28C7\u2800\u28FC\u28FF\u28FF\u28C6\u28B7\u28F4\u28FF\u28FF\u284F\u28DB\u2849\u2800${w} \u28B8\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u28B8\u28FF\u28FF\u2800\u2800\u2800\u2800\u2800\u28FF\u28FF\u2847\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u2847\u2800\u2800\u2800\u28FE\u28FF\u28FF\u28E7\u2800\u2800\u2800${w}\u28B8\u281F\u2880\u28F4\u28FF\u28FF\u28FF\u28FF\u28E6\u2840\u28E0\u28FE\u28FF\u28FF\u28FF\u28FF\u28E6\u2859\u28BF${r}
${b}\u2800\u2819\u28B7\u28EE\u28B8\u28FF\u28FF\u28FF\u28FF\u28F7\u28EF\u28DF\u28CF\u28FC\u28F7\u28C5\u283E${w} \u28B8\u28FF\u28C7\u28C0\u28C0\u28C0\u2800\u28B8\u28FF\u28FF\u2800\u2800\u2800\u2800\u2800\u28FF\u28FF\u2847\u2800\u2800\u2800\u28E0\u28FF\u28FF\u281F\u2801\u2800\u2800\u28FC\u28FF\u285F\u28FF\u28FF\u28C6\u2800\u2800${w}\u2800\u2800\u28FF\u28FF\u280B\u2800\u2808\u283B\u28FF\u2847\u28FF\u28FF\u28C5\u28C0\u28C0\u285B\u281B\u2803\u2800${r}
${b}\u2800\u2800\u2800\u2801\u28B8\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u280B\u2800${w} \u28B8\u28FF\u287F\u283F\u283F\u283F\u2800\u28B8\u28FF\u28FF\u2800\u2800\u2800\u2800\u2800\u28FF\u28FF\u2847\u2800\u28E0\u28FE\u28FF\u281F\u2801\u2800\u2800\u2800\u28F0\u28FF\u28FF\u28C1\u28F8\u28FF\u28FF\u2844\u2800${w}\u2800\u2800\u28FF\u28FF \u2800\u2800 \u28FF\u28FF\u2888\u28DB\u283F\u283F\u283F\u28FF\u28F7\u2844\u2800${r}
${b}\u2800\u2800\u2800\u2800\u2838\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u28FF\u28C9\u285F\u2800\u2800${w} \u28B8\u28FF\u28E7\u28E4\u28E4\u28E4\u28E4\u28B8\u28FF\u28FF\u28E6\u28E4\u28E4\u28E4\u2844\u28FF\u28FF\u2847\u28FE\u28FF\u28FF\u28E7\u28E4\u28E4\u28E4\u2844\u28B0\u28FF\u28FF\u281F\u281B\u281B\u283B\u28FF\u28FF\u2844${w}\u28A0\u2840\u283B\u28FF\u28FF\u28E6\u28F4\u28FF\u28FF\u2807\u28BF\u28FF\u28E6\u28E4\u28E4\u28FF\u28FF\u2807\u28E0${r}
${b}\u2800\u2800\u2800\u2800\u28B0\u2848\u281B\u283F\u28FF\u28FF\u28FF\u28FF\u28FF\u280B\u2800  ${w} \u2818\u281B\u281B\u281B\u281B\u281B\u281B\u2808\u281B\u281B\u281B\u281B\u281B\u281B\u2803\u281B\u281B\u2803\u281B\u281B\u281B\u281B\u281B\u281B\u281B\u2803\u281B\u281B\u2803\u2800\u2800\u2800\u2800\u2819\u281B\u2803${w}\u2818\u281B\u2800\u2808\u281B\u281B\u281B\u281B\u2801\u2800\u2800\u2819\u281B\u281B\u281B\u281B\u2801\u281A\u281B${r}
${b}\u2800\u2800\u2800\u2800\u28B8\u28FF\u2866\u2800\u2800\u2809\u281B\u283F\u2803\u2800\u2800\u2800 ${w} \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800${w}\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800${r}
`
  ];
  const randomBanner = banners[Math.floor(Math.random() * banners.length)];
  console.log(randomBanner);
  if (version) {
    console.log(`${versionColor}Version: ${version}${r}`);
  }
  if (!skipUpdateCheck) {
    try {
      await checkAndShowUpdateNotification(version);
    } catch (error) {
    }
  }
}

// src/utils/get-config.ts
import { logger as logger9 } from "@elizaos/core";
import dotenv2 from "dotenv";
import path9 from "path";
import { existsSync as existsSync7, promises as fs7 } from "fs";
import * as clack3 from "@clack/prompts";
import { z } from "zod";
var postgresConfigSchema = z.object({
  type: z.literal("postgres"),
  config: z.object({
    url: z.string().optional()
  })
});
var pgliteConfigSchema = z.object({
  type: z.literal("pglite"),
  config: z.object({
    dataDir: z.string()
  })
});
var SAMPLE_ENV_TEMPLATE = `### elizaOS Environment Variables ###
# To get started, copy this file to .env, or make a .env and add the settings you'd like to override
# Please read the comments for each of the configurations

## The only thing you ABSOLUTELY NEED to get up and running is one of the model provider keys, 
## i.e. OPENAI_API_KEY or ANTHROPIC_API_KEY, or setup the local-ai or ollama plugin
## Everything else is optional, and most settings and secrets can be configured in your agent or through the GUI
## For multi-agent, each agent will need keys for the various services it is connected to
-------------------------------
## You can use the .env or environment variables generally for shared keys, such as to model providers, 
## database, etc, with scoped keys for services such as Telegram, Discord, etc

## MODEL PROVIDER KEYS ##
## Eliza is compatible with a wide array of model providers. Many have OpenAI compatible APIs, 
## and you can use them by overriding the base URL

## NOTE: You will need a provider that provides embeddings. So even if you use Claude, you will 
## need to get embeddings using another provider, for example openai or our local-ai plugin

# OpenAI Configuration
OPENAI_API_KEY=
## Use this to override the openai endpoint, for example for using together.ai, fireworks or other providers
## Optional overrides:
--------------------------------
# OPENAI_BASE_URL=
# OPENAI_SMALL_MODEL=gpt-4o-mini
# OPENAI_LARGE_MODEL=gpt-4o
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_EMBEDDING_URL=
# OPENAI_EMBEDDING_DIMENSIONS=1536
# OPENAI_IMAGE_DESCRIPTION_MODEL=gpt-4o-mini
# OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS=8192

# Anthropic Configuration
## By default in most of our starter kits, Anthropic will take precedence over OpenAI in handling requests
## Anthropic does not handle embeddings, so you may wish to use OpenAI for that, even while Claude is handling text generation
--------------------------------
ANTHROPIC_API_KEY=
# Optional overrides:
# ANTHROPIC_SMALL_MODEL=claude-3-5-haiku-latest
# ANTHROPIC_LARGE_MODEL=claude-3-5-sonnet-latest


# Ollama Configuration
## Highly recommended to use gemma3:latest for text generation
--------------------------------
# OLLAMA_API_ENDPOINT=http://localhost:11434/api
# OLLAMA_SMALL_MODEL=gemma3:latest
# OLLAMA_MEDIUM_MODEL=gemma3:latest
# OLLAMA_LARGE_MODEL=gemma3:latest


# Local AI Configuration
## REMEMBER A GOOD AMOUNT OF VRAM IS NEEDED FOR THE LARGE LOCAL MODELS
--------------------------------
# LOCAL_SMALL_MODEL=DeepHermes-3-Llama-3-3B-Preview-q4.gguf
# LOCAL_LARGE_MODEL=DeepHermes-3-Llama-3-70B-Preview-q4.gguf
# LOCAL_EMBEDDING_MODEL=bge-small-en-v1.5.Q4_K_M.gguf




# Highly recommended to use nomic-embed-text for embeddings
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text 

### DATABASE ###
# By default, Eliza will use a local pglite instance
# If you fill out POSTGRES_URL, the agent will connect to your postgres instance instead of using the local path

# You can override the pglite data directory
PGLITE_DATA_DIR=

# Fill this out if you want to use Postgres
POSTGRES_URL=

### LOGGING CONFIGURATION ###
# Logging Configuration (supported: fatal, error, warn, info, debug, trace | default: info)
LOG_LEVEL=


# Sentry Configuration
--------------------------------
## DO NOT CHANGE THIS UNLESS YOU KNOW WHAT YOU ARE DOING
--------------------------------
# Sentry is a tool for monitoring and logging errors and exceptions
# It is used to track errors and exceptions in the agent
--------------------------------
# Sentry Configuration
SENTRY_LOGGING=true
SENTRY_DSN=
SENTRY_ENVIRONMENT=
SENTRY_TRACES_SAMPLE_RATE=
SENTRY_SEND_DEFAULT_PII=

`;
function isValidPostgresUrl(url) {
  if (!url || typeof url !== "string") return false;
  try {
    const parsedUrl = new URL(url);
    return parsedUrl.protocol === "postgresql:" && !!parsedUrl.hostname && !!parsedUrl.pathname && parsedUrl.pathname !== "/";
  } catch {
    const patterns = [
      /^postgresql:\/\/[^:]+:[^@]+@[^:]+:\d+\/\w+$/,
      /^postgresql:\/\/[^:]+:[^@]+@[^\/]+\/[^?]+(\?.*)?$/,
      /^postgresql:\/\/.*@.*:\d+\/.*$/
    ];
    return patterns.some((pattern) => pattern.test(url));
  }
}
async function getElizaDirectories(targetProjectDir) {
  const userEnv = UserEnvironment.getInstance();
  const paths = await userEnv.getPathInfo();
  const projectRoot = targetProjectDir || paths.monorepoRoot || process.cwd();
  const elizaDir = targetProjectDir ? path9.resolve(targetProjectDir, ".eliza") : paths.elizaDir;
  const envFilePath = targetProjectDir ? path9.resolve(targetProjectDir, ".env") : paths.envFilePath;
  logger9.debug("Eliza directories:", {
    elizaDir,
    projectRoot,
    targetProjectDir: targetProjectDir || "none"
  });
  const defaultElizaDbDir = path9.resolve(projectRoot, ".eliza", ".elizadb");
  const elizaDbDir = await resolvePgliteDir(void 0, defaultElizaDbDir);
  return { elizaDir, elizaDbDir, envFilePath };
}
async function ensureDir(dirPath) {
  if (!existsSync7(dirPath)) {
    await fs7.mkdir(dirPath, { recursive: true });
    logger9.debug(`Created directory: ${dirPath}`);
  }
}
async function setupEnvFile(envFilePath) {
  try {
    const envExists = existsSync7(envFilePath);
    if (!envExists) {
      const mergedVars = mergeProcessEnvWithTemplate(SAMPLE_ENV_TEMPLATE);
      const formattedContent = formatEnvFileWithTemplate(mergedVars, SAMPLE_ENV_TEMPLATE);
      await fs7.writeFile(envFilePath, formattedContent, "utf8");
      const processEnvCount = Object.keys(process.env).filter(
        (key) => process.env[key] && process.env[key].trim() !== ""
      ).length;
      logger9.info(
        `[Config] Created .env file with ${processEnvCount} variables from process.env merged with example variables at: ${envFilePath}`
      );
    } else {
      const content = await fs7.readFile(envFilePath, "utf8");
      const trimmedContent = content.trim();
      if (trimmedContent === "") {
        const mergedVars = mergeProcessEnvWithTemplate(SAMPLE_ENV_TEMPLATE);
        const formattedContent = formatEnvFileWithTemplate(mergedVars, SAMPLE_ENV_TEMPLATE);
        await fs7.writeFile(envFilePath, formattedContent, "utf8");
        const processEnvCount = Object.keys(process.env).filter(
          (key) => process.env[key] && process.env[key].trim() !== ""
        ).length;
        logger9.info(
          `[Config] Populated empty .env file with ${processEnvCount} variables from process.env merged with example variables at: ${envFilePath}`
        );
      } else {
        logger9.debug(`[Config] .env file already exists and has content at: ${envFilePath}`);
      }
    }
  } catch (error) {
    logger9.error("Error setting up .env file:", {
      error: error instanceof Error ? error.message : String(error),
      envFilePath
    });
    throw error;
  }
}
async function ensureElizaDir(targetProjectDir) {
  const dirs = await getElizaDirectories(targetProjectDir);
  await ensureDir(dirs.elizaDir);
  const registryCachePath = path9.join(dirs.elizaDir, "registry-cache.json");
  const configPath = path9.join(dirs.elizaDir, "config.json");
  if (!existsSync7(registryCachePath)) {
    await fs7.writeFile(registryCachePath, JSON.stringify({}, null, 2), "utf8");
    logger9.debug(`Created registry cache file: ${registryCachePath}`);
  }
  if (!existsSync7(configPath)) {
    await fs7.writeFile(configPath, JSON.stringify({ version: "1.0.0" }, null, 2), "utf8");
    logger9.debug(`Created config file: ${configPath}`);
  }
  return dirs;
}
async function setupPgLite(dbDir, envPath, targetProjectDir) {
  const dirs = await ensureElizaDir(targetProjectDir);
  const { elizaDbDir, envFilePath } = dirs;
  const targetDbDir = dbDir || elizaDbDir;
  const targetEnvPath = envPath || envFilePath;
  try {
    await ensureDir(targetDbDir);
    logger9.debug("[PGLite] Created database directory:", targetDbDir);
    await setupEnvFile(targetEnvPath);
    await storePgliteDataDir(targetDbDir, targetEnvPath);
    logger9.success("PGLite configuration saved");
  } catch (error) {
    logger9.error("Error setting up PGLite directory:", {
      error: error instanceof Error ? error.message : String(error),
      elizaDbDir,
      envFilePath
    });
    throw error;
  }
}
async function storePostgresUrl(url, envFilePath) {
  if (!url) return;
  try {
    let content = "";
    if (existsSync7(envFilePath)) {
      content = await fs7.readFile(envFilePath, "utf8");
    }
    const lines = content.split("\n").filter((line) => !line.startsWith("POSTGRES_URL="));
    lines.push(`POSTGRES_URL=${url}`);
    await fs7.writeFile(envFilePath, lines.join("\n"), "utf8");
    process.env.POSTGRES_URL = url;
    logger9.success("Postgres URL saved to configuration");
  } catch (error) {
    logger9.error("Error saving database configuration:", error);
    throw error;
  }
}
async function storePgliteDataDir(dataDir, envFilePath) {
  if (!dataDir) return;
  try {
    let content = "";
    if (existsSync7(envFilePath)) {
      content = await fs7.readFile(envFilePath, "utf8");
    }
    const lines = content.split("\n").filter((line) => !line.startsWith("PGLITE_DATA_DIR="));
    lines.push(`PGLITE_DATA_DIR=${dataDir}`);
    await fs7.writeFile(envFilePath, lines.join("\n"), "utf8");
    process.env.PGLITE_DATA_DIR = dataDir;
    logger9.success("PGLite data directory saved to configuration");
  } catch (error) {
    logger9.error("Error saving PGLite configuration:", error);
    throw error;
  }
}
async function promptAndStorePostgresUrl(envFilePath) {
  clack3.intro("\u{1F5C4}\uFE0F  PostgreSQL Configuration");
  const response = await clack3.text({
    message: "Enter your Postgres URL:",
    placeholder: "postgresql://user:password@host:port/dbname",
    validate: (value) => {
      if (value.trim() === "") return "Postgres URL cannot be empty";
      const isValid = isValidPostgresUrl(value);
      if (!isValid) {
        return "Invalid URL format. Expected: postgresql://user:password@host:port/dbname.";
      }
      return void 0;
    }
  });
  if (clack3.isCancel(response)) {
    clack3.cancel("Operation cancelled.");
    return null;
  }
  const spinner2 = clack3.spinner();
  spinner2.start("Saving PostgreSQL configuration...");
  try {
    await storePostgresUrl(response, envFilePath);
    spinner2.stop("PostgreSQL configuration saved successfully!");
    clack3.outro("\u2713 Database connection configured");
    return response;
  } catch (error) {
    spinner2.stop("Failed to save configuration");
    clack3.log.error(`Error: ${error instanceof Error ? error.message : String(error)}`);
    return null;
  }
}
function isValidOpenAIKey(key) {
  if (!key || typeof key !== "string") return false;
  return key.startsWith("sk-") && key.length >= 20;
}
function isValidAnthropicKey(key) {
  if (!key || typeof key !== "string") return false;
  return key.startsWith("sk-ant-") && key.length >= 20;
}
function isValidGoogleKey(key) {
  if (!key || typeof key !== "string") return false;
  return key.length === 39 && /^[A-Za-z0-9_-]+$/.test(key);
}
async function storeOpenAIKey(key, envFilePath) {
  if (!key) return;
  try {
    let content = "";
    if (existsSync7(envFilePath)) {
      content = await fs7.readFile(envFilePath, "utf8");
    }
    const lines = content.split("\n").filter((line) => !line.startsWith("OPENAI_API_KEY="));
    lines.push(`OPENAI_API_KEY=${key}`);
    await fs7.writeFile(envFilePath, lines.join("\n"), "utf8");
    process.env.OPENAI_API_KEY = key;
    logger9.success("OpenAI API key saved to configuration");
  } catch (error) {
    logger9.error("Error saving OpenAI API key:", error);
    throw error;
  }
}
async function storeGoogleKey(key, envFilePath) {
  if (!key) return;
  try {
    let content = "";
    if (existsSync7(envFilePath)) {
      content = await fs7.readFile(envFilePath, "utf8");
    }
    const lines = content.split("\n").filter((line) => !line.startsWith("GOOGLE_GENERATIVE_AI_API_KEY="));
    lines.push(`GOOGLE_GENERATIVE_AI_API_KEY=${key}`);
    await fs7.writeFile(envFilePath, lines.join("\n"), "utf8");
    process.env.GOOGLE_GENERATIVE_AI_API_KEY = key;
    logger9.success("Google Generative AI API key saved to configuration");
  } catch (error) {
    logger9.error("Error saving Google API key:", error);
    throw error;
  }
}
async function storeAnthropicKey(key, envFilePath) {
  if (!key) return;
  try {
    let content = "";
    if (existsSync7(envFilePath)) {
      content = await fs7.readFile(envFilePath, "utf8");
    }
    const lines = content.split("\n").filter((line) => !line.startsWith("ANTHROPIC_API_KEY="));
    lines.push(`ANTHROPIC_API_KEY=${key}`);
    await fs7.writeFile(envFilePath, lines.join("\n"), "utf8");
    process.env.ANTHROPIC_API_KEY = key;
    logger9.success("Anthropic API key saved to configuration");
  } catch (error) {
    logger9.error("Error saving Anthropic API key:", error);
    throw error;
  }
}
async function promptAndStoreProviderConfig(config, envFilePath) {
  clack3.intro(`${config.icon} ${config.name} Configuration`);
  if (config.noteText) {
    clack3.note(config.noteText, "API Key Information");
  }
  const results = {};
  for (const input of config.inputs) {
    const promptFn = input.type === "password" ? clack3.password : clack3.text;
    const promptConfig = {
      message: input.message,
      validate: input.validate
    };
    if (input.placeholder) promptConfig.placeholder = input.placeholder;
    if (input.initialValue) promptConfig.initialValue = input.initialValue;
    const response = await promptFn(promptConfig);
    if (clack3.isCancel(response)) {
      clack3.cancel("Operation cancelled.");
      return null;
    }
    results[input.key] = input.type === "text" ? response.trim() : response;
  }
  const spinner2 = clack3.spinner();
  spinner2.start(`Saving ${config.name} configuration...`);
  try {
    await config.storeFunction(results, envFilePath);
    spinner2.stop(`${config.name} configuration saved successfully!`);
    clack3.outro(`\u2713 ${config.successMessage}`);
    return results;
  } catch (error) {
    spinner2.stop("Failed to save configuration");
    clack3.log.error(`Error: ${error instanceof Error ? error.message : String(error)}`);
    return null;
  }
}
async function promptAndStoreOpenAIKey(envFilePath) {
  const config = {
    name: "OpenAI API",
    icon: "\u{1F916}",
    noteText: "Get your API key from: https://platform.openai.com/api-keys",
    inputs: [
      {
        key: "key",
        message: "Enter your OpenAI API key:",
        type: "password",
        validate: (value) => {
          if (value.trim() === "") return "OpenAI API key cannot be empty";
          return void 0;
        }
      }
    ],
    storeFunction: async (results, envPath) => {
      const isValid = isValidOpenAIKey(results.key);
      if (!isValid) {
        clack3.log.warn("Invalid API key format detected. Expected format: sk-...");
        clack3.log.warn("The key has been saved but may not work correctly.");
      }
      await storeOpenAIKey(results.key, envPath);
    },
    successMessage: "OpenAI integration configured"
  };
  const result = await promptAndStoreProviderConfig(config, envFilePath);
  return result?.key || null;
}
async function promptAndStoreAnthropicKey(envFilePath) {
  const config = {
    name: "Anthropic Claude",
    icon: "\u{1F916}",
    noteText: "Get your API key from: https://console.anthropic.com/settings/keys",
    inputs: [
      {
        key: "key",
        message: "Enter your Anthropic API key:",
        type: "password",
        validate: (value) => {
          if (value.trim() === "") return "Anthropic API key cannot be empty";
          return void 0;
        }
      }
    ],
    storeFunction: async (results, envPath) => {
      const isValid = isValidAnthropicKey(results.key);
      if (!isValid) {
        clack3.log.warn("Invalid API key format detected. Expected format: sk-ant-...");
        clack3.log.warn("The key has been saved but may not work correctly.");
      }
      await storeAnthropicKey(results.key, envPath);
    },
    successMessage: "Claude integration configured"
  };
  const result = await promptAndStoreProviderConfig(config, envFilePath);
  return result?.key || null;
}
function isValidOllamaEndpoint(endpoint) {
  if (!endpoint || typeof endpoint !== "string") return false;
  try {
    const url = new URL(endpoint);
    return url.protocol === "http:" || url.protocol === "https:";
  } catch {
    return false;
  }
}
async function storeOllamaConfig(config, envFilePath) {
  if (!config.endpoint || !config.model) return;
  try {
    let content = "";
    if (existsSync7(envFilePath)) {
      content = await fs7.readFile(envFilePath, "utf8");
    }
    const lines = content.split("\n").filter(
      (line) => !line.startsWith("OLLAMA_API_ENDPOINT=") && !line.startsWith("OLLAMA_MODEL=") && !line.startsWith("USE_OLLAMA_TEXT_MODELS=")
    );
    lines.push(`OLLAMA_API_ENDPOINT=${config.endpoint}`);
    lines.push(`OLLAMA_MODEL=${config.model}`);
    lines.push("USE_OLLAMA_TEXT_MODELS=true");
    await fs7.writeFile(envFilePath, lines.join("\n"), "utf8");
    process.env.OLLAMA_API_ENDPOINT = config.endpoint;
    process.env.OLLAMA_MODEL = config.model;
    process.env.USE_OLLAMA_TEXT_MODELS = "true";
    logger9.success("Ollama configuration saved to configuration");
  } catch (error) {
    logger9.error("Error saving Ollama configuration:", error);
    throw error;
  }
}
async function promptAndStoreOllamaEmbeddingConfig(envFilePath) {
  let existingEndpoint = process.env.OLLAMA_API_ENDPOINT;
  const config = {
    name: "Ollama Embeddings",
    icon: "\u{1F999}",
    noteText: "Select an embedding model for Ollama.\nPopular options: nomic-embed-text, mxbai-embed-large\nMake sure the model is pulled: ollama pull <model-name>",
    inputs: [
      {
        key: "endpoint",
        message: "Enter your Ollama API endpoint:",
        placeholder: "http://localhost:11434",
        initialValue: existingEndpoint || "http://localhost:11434",
        type: "text",
        validate: (value) => {
          if (value.trim() === "") return "Ollama endpoint cannot be empty";
          if (!isValidOllamaEndpoint(value))
            return "Invalid URL format (http:// or https:// required)";
          return void 0;
        }
      },
      {
        key: "embeddingModel",
        message: "Enter your Ollama embedding model:",
        placeholder: "nomic-embed-text",
        initialValue: "nomic-embed-text",
        type: "text",
        validate: (value) => {
          if (value.trim() === "") return "Embedding model name cannot be empty";
          return void 0;
        }
      }
    ],
    storeFunction: async (results, envPath) => {
      try {
        let content = "";
        if (existsSync7(envPath)) {
          content = await fs7.readFile(envPath, "utf8");
        }
        const lines = content.split("\n").filter(
          (line) => !line.startsWith("OLLAMA_EMBEDDING_MODEL=") && !line.startsWith("USE_OLLAMA_EMBEDDINGS=")
        );
        const endpointPattern = /^OLLAMA_API_ENDPOINT=(.*)$/m;
        const existingEndpointMatch = content.match(endpointPattern);
        if (existingEndpointMatch) {
          if (results.endpoint !== existingEndpointMatch[1]) {
            const updatedLines = lines.map((line) => {
              if (line.startsWith("OLLAMA_API_ENDPOINT=")) {
                return `OLLAMA_API_ENDPOINT=${results.endpoint}`;
              }
              return line;
            });
            lines.length = 0;
            lines.push(...updatedLines);
          }
        } else {
          lines.push(`OLLAMA_API_ENDPOINT=${results.endpoint}`);
        }
        lines.push(`OLLAMA_EMBEDDING_MODEL=${results.embeddingModel}`);
        lines.push("USE_OLLAMA_EMBEDDINGS=true");
        await fs7.writeFile(envPath, lines.join("\n"), "utf8");
        process.env.OLLAMA_API_ENDPOINT = results.endpoint;
        process.env.OLLAMA_EMBEDDING_MODEL = results.embeddingModel;
        process.env.USE_OLLAMA_EMBEDDINGS = "true";
        logger9.success("Ollama embedding configuration saved");
      } catch (error) {
        logger9.error("Error saving Ollama embedding configuration:", error);
        throw error;
      }
    },
    successMessage: "Ollama embedding model configured"
  };
  return await promptAndStoreProviderConfig(
    config,
    envFilePath
  );
}
async function promptAndStoreOllamaConfig(envFilePath) {
  const config = {
    name: "Ollama",
    icon: "\u{1F999}",
    noteText: "Make sure Ollama is installed and running on your system.\nDefault endpoint: http://localhost:11434\nGet started: https://ollama.ai/",
    inputs: [
      {
        key: "endpoint",
        message: "Enter your Ollama API endpoint:",
        placeholder: "http://localhost:11434",
        initialValue: "http://localhost:11434",
        type: "text",
        validate: (value) => {
          if (value.trim() === "") return "Ollama endpoint cannot be empty";
          if (!isValidOllamaEndpoint(value))
            return "Invalid URL format (http:// or https:// required)";
          return void 0;
        }
      },
      {
        key: "model",
        message: "Enter your preferred Ollama model:",
        placeholder: "llama2",
        initialValue: "llama2",
        type: "text",
        validate: (value) => {
          if (value.trim() === "") return "Model name cannot be empty";
          return void 0;
        }
      }
    ],
    storeFunction: async (results, envPath) => {
      await storeOllamaConfig({ endpoint: results.endpoint, model: results.model }, envPath);
    },
    successMessage: "Ollama integration configured"
  };
  return await promptAndStoreProviderConfig(
    config,
    envFilePath
  );
}
async function promptAndStoreGoogleKey(envFilePath) {
  const config = {
    name: "Google Generative AI",
    icon: "\u{1F916}",
    noteText: "Get your API key from: https://aistudio.google.com/apikey",
    inputs: [
      {
        key: "key",
        message: "Enter your Google Generative AI API key:",
        type: "password",
        validate: (value) => {
          if (value.trim() === "") return "Google API key cannot be empty";
          return void 0;
        }
      }
    ],
    storeFunction: async (results, envPath) => {
      const isValid = isValidGoogleKey(results.key);
      if (!isValid) {
        clack3.log.warn(
          "Invalid API key format detected. Expected format: 39 character alphanumeric key"
        );
        clack3.log.warn("The key has been saved but may not work correctly.");
      }
      await storeGoogleKey(results.key, envPath);
    },
    successMessage: "Google Generative AI integration configured"
  };
  const result = await promptAndStoreProviderConfig(config, envFilePath);
  return result?.key || null;
}
function isValidOpenRouterKey(key) {
  if (!key || typeof key !== "string") return false;
  return key.startsWith("sk-or-") && key.length > 10;
}
async function storeOpenRouterKey(key, envFilePath) {
  if (!key) return;
  try {
    let content = "";
    if (existsSync7(envFilePath)) {
      content = await fs7.readFile(envFilePath, "utf8");
    }
    const lines = content.split("\n").filter((line) => !line.startsWith("OPENROUTER_API_KEY="));
    lines.push(`OPENROUTER_API_KEY=${key}`);
    await fs7.writeFile(envFilePath, lines.join("\n"), "utf8");
    process.env.OPENROUTER_API_KEY = key;
    logger9.success("OpenRouter API key saved to configuration");
  } catch (error) {
    logger9.error("Error saving OpenRouter API key:", error);
    throw error;
  }
}
async function promptAndStoreOpenRouterKey(envFilePath) {
  const config = {
    name: "OpenRouter",
    icon: "\u{1F504}",
    noteText: "Get your API key from: https://openrouter.ai/keys",
    inputs: [
      {
        key: "key",
        message: "Enter your OpenRouter API key:",
        type: "password",
        validate: (value) => {
          if (value.trim() === "") return "OpenRouter API key cannot be empty";
          return void 0;
        }
      }
    ],
    storeFunction: async (results, envPath) => {
      const isValid = isValidOpenRouterKey(results.key);
      if (!isValid) {
        clack3.log.warn("Invalid API key format detected. Expected format: sk-or-...");
        clack3.log.warn("The key has been saved but may not work correctly.");
      }
      await storeOpenRouterKey(results.key, envPath);
    },
    successMessage: "OpenRouter integration configured"
  };
  const result = await promptAndStoreProviderConfig(config, envFilePath);
  return result?.key || null;
}
async function configureDatabaseSettings(reconfigure = false) {
  const { elizaDbDir, envFilePath } = await ensureElizaDir();
  await setupEnvFile(envFilePath);
  await loadEnvironment(path9.dirname(envFilePath));
  let postgresUrl = process.env.POSTGRES_URL;
  const pgliteDataDir = await resolvePgliteDir(void 0, elizaDbDir);
  logger9.debug(`Configuration check - POSTGRES_URL: ${postgresUrl ? "SET" : "NOT SET"}`);
  logger9.debug(`Configuration check - PGLITE_DATA_DIR: ${pgliteDataDir ? "SET" : "NOT SET"}`);
  logger9.debug(`Configuration check - reconfigure: ${reconfigure}`);
  if (process.env.POSTGRES_URL) {
    console.log("BYPASS: Using postgres URL from environment variable");
    return process.env.POSTGRES_URL;
  }
  if (pgliteDataDir && !reconfigure) {
    logger9.debug(`Using existing PGLite configuration: ${pgliteDataDir}`);
    await ensureDir(pgliteDataDir);
    return null;
  }
  console.log("BYPASS: No database configuration found, defaulting to pglite");
  await setupPgLite(elizaDbDir, envFilePath);
  return null;
}
var rawConfigSchema = z.object({
  $schema: z.string().optional(),
  database: z.discriminatedUnion("type", [postgresConfigSchema, pgliteConfigSchema]),
  plugins: z.object({
    registry: z.string().url(),
    installed: z.array(z.string())
  }),
  paths: z.object({
    knowledge: z.string()
  })
}).strict();
var configSchema = rawConfigSchema.extend({
  resolvedPaths: z.object({
    knowledge: z.string()
  })
});
async function resolveConfigPaths(cwd, config) {
  try {
    return configSchema.parse({
      ...config,
      resolvedPaths: {
        knowledge: path9.resolve(cwd, config.paths.knowledge)
      }
    });
  } catch (error) {
    logger9.error("Failed to resolve config paths:", error);
    throw new Error("Invalid configuration: failed to resolve paths");
  }
}
async function loadEnvironment(projectDir = process.cwd()) {
  const envPath = resolveEnvFile(projectDir);
  if (existsSync7(envPath)) {
    dotenv2.config({ path: envPath });
  }
}
function mergeProcessEnvWithTemplate(templateContent) {
  const result = {};
  const processedKeys = /* @__PURE__ */ new Set();
  const templateLines = templateContent.split("\n");
  const templateVars = {};
  for (const line of templateLines) {
    const trimmedLine = line.trim();
    if (trimmedLine && !trimmedLine.startsWith("#") && trimmedLine.includes("=")) {
      const equalIndex = trimmedLine.indexOf("=");
      const key = trimmedLine.substring(0, equalIndex).trim();
      const value = trimmedLine.substring(equalIndex + 1).trim();
      if (key) {
        templateVars[key] = value;
      }
    }
  }
  for (const [key, value] of Object.entries(process.env)) {
    if (value && value.trim() !== "") {
      result[key] = value;
      processedKeys.add(key);
    }
  }
  for (const [key, value] of Object.entries(templateVars)) {
    if (!processedKeys.has(key)) {
      result[key] = value;
      processedKeys.add(key);
    }
  }
  return result;
}
function formatEnvFileWithTemplate(envVars, templateContent) {
  const lines = [];
  const processedKeys = /* @__PURE__ */ new Set();
  const templateLines = templateContent.split("\n");
  for (const line of templateLines) {
    const trimmedLine = line.trim();
    if (!trimmedLine || trimmedLine.startsWith("#") || !trimmedLine.includes("=")) {
      lines.push(line);
    } else {
      const equalIndex = trimmedLine.indexOf("=");
      const key = trimmedLine.substring(0, equalIndex).trim();
      if (key && envVars.hasOwnProperty(key)) {
        lines.push(`${key}=${envVars[key]}`);
        processedKeys.add(key);
      } else {
        lines.push(line);
      }
    }
  }
  const newVars = [];
  for (const [key, value] of Object.entries(envVars)) {
    if (!processedKeys.has(key)) {
      newVars.push(`${key}=${value}`);
    }
  }
  if (newVars.length > 0) {
    lines.push("");
    lines.push("### Additional Environment Variables from Runtime ###");
    lines.push("# Variables found in process.env that were not in the template");
    lines.push(...newVars);
  }
  return lines.join("\n");
}

// src/utils/get-package-info.ts
async function getPackageVersion(packageName) {
  return UserEnvironment.getInstance().getPackageVersion(packageName);
}
async function getLocalPackages() {
  return UserEnvironment.getInstance().getLocalPackages();
}
async function getPackageInfo() {
  const { packageJsonPath } = await UserEnvironment.getInstance().getPathInfo();
  try {
    const fileContent = await import("fs/promises").then(
      (fs11) => fs11.readFile(packageJsonPath, "utf8")
    );
    return JSON.parse(fileContent);
  } catch (error) {
    if (error instanceof Error) {
      if (error.code === "ENOENT") {
        throw new Error(`Error: Could not find package.json at ${packageJsonPath}`);
      }
      if (error instanceof SyntaxError) {
        throw new Error(
          `Error: Invalid JSON in package.json at ${packageJsonPath}. Details: ${error.message}`
        );
      }
      throw new Error(
        `Error reading or parsing package.json at ${packageJsonPath}: ${error.message}`
      );
    }
    throw new Error(
      `An unexpected error occurred while reading or parsing package.json at ${packageJsonPath}`
    );
  }
}

// src/utils/github.ts
import { promises as fs8 } from "fs";
import path10 from "path";
import { logger as logger10 } from "@elizaos/core";
import { existsSync as existsSync8 } from "fs";
import { execa as execa5 } from "execa";
import * as clack4 from "@clack/prompts";
var GITHUB_API_URL = "https://api.github.com";
async function validateGitHubToken(token) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/user`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    if (response.status === 200) {
      const userData = await response.json();
      logger10.success(`Authenticated as ${userData.login}`);
      return true;
    }
    return false;
  } catch (error) {
    logger10.error(
      `Failed to validate GitHub token: ${error instanceof Error ? error.message : String(error)}`
    );
    return false;
  }
}
async function forkExists(token, repo, username) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/repos/${username}/${repo}`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    return response.status === 200;
  } catch (error) {
    return false;
  }
}
async function forkRepository(token, owner, repo) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/forks`, {
      method: "POST",
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    if (response.status === 202) {
      const forkData = await response.json();
      logger10.success(`Forked ${owner}/${repo} to ${forkData.full_name}`);
      return forkData.full_name;
    }
    logger10.error(`Failed to fork repository: ${response.statusText}`);
    return null;
  } catch (error) {
    logger10.error(
      `Failed to fork repository: ${error instanceof Error ? error.message : String(error)}`
    );
    return null;
  }
}
async function branchExists(token, owner, repo, branch) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/branches/${branch}`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    return response.status === 200;
  } catch (error) {
    return false;
  }
}
async function createBranch(token, owner, repo, branch, baseBranch = "main") {
  try {
    let baseResponse = await fetch(
      `${GITHUB_API_URL}/repos/${owner}/${repo}/git/ref/heads/${baseBranch}`,
      {
        headers: {
          Authorization: `token ${token}`,
          Accept: "application/vnd.github.v3+json"
        }
      }
    );
    if (baseResponse.status !== 200) {
      logger10.warn(`Base branch '${baseBranch}' not found, checking for alternative branches...`);
      const branchesResponse = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/branches`, {
        headers: {
          Authorization: `token ${token}`,
          Accept: "application/vnd.github.v3+json"
        }
      });
      if (branchesResponse.status === 200) {
        const branches = await branchesResponse.json();
        if (branches && branches.length > 0) {
          const alternativeBranch = branches[0].name;
          logger10.info(`Using '${alternativeBranch}' as base branch instead`);
          baseResponse = await fetch(
            `${GITHUB_API_URL}/repos/${owner}/${repo}/git/ref/heads/${alternativeBranch}`,
            {
              headers: {
                Authorization: `token ${token}`,
                Accept: "application/vnd.github.v3+json"
              }
            }
          );
        } else {
          logger10.info("No branches found in repository, creating initial commit");
          const blobResponse = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/git/blobs`, {
            method: "POST",
            headers: {
              Authorization: `token ${token}`,
              Accept: "application/vnd.github.v3+json",
              "Content-Type": "application/json"
            },
            body: JSON.stringify({
              content: "# Repository initialized by Eliza CLI",
              encoding: "utf-8"
            })
          });
          if (blobResponse.status !== 201) {
            logger10.error("Failed to create initial blob");
            return false;
          }
          const blobData = await blobResponse.json();
          const blobSha = blobData.sha;
          const treeResponse = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/git/trees`, {
            method: "POST",
            headers: {
              Authorization: `token ${token}`,
              Accept: "application/vnd.github.v3+json",
              "Content-Type": "application/json"
            },
            body: JSON.stringify({
              tree: [
                {
                  path: "README.md",
                  mode: "100644",
                  type: "blob",
                  sha: blobSha
                }
              ]
            })
          });
          if (treeResponse.status !== 201) {
            logger10.error("Failed to create initial tree");
            return false;
          }
          const treeData = await treeResponse.json();
          const treeSha = treeData.sha;
          const commitResponse = await fetch(
            `${GITHUB_API_URL}/repos/${owner}/${repo}/git/commits`,
            {
              method: "POST",
              headers: {
                Authorization: `token ${token}`,
                Accept: "application/vnd.github.v3+json",
                "Content-Type": "application/json"
              },
              body: JSON.stringify({
                message: "Initial commit",
                tree: treeSha
              })
            }
          );
          if (commitResponse.status !== 201) {
            logger10.error("Failed to create initial commit");
            return false;
          }
          const commitData = await commitResponse.json();
          const commitSha = commitData.sha;
          const refResponse = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/git/refs`, {
            method: "POST",
            headers: {
              Authorization: `token ${token}`,
              Accept: "application/vnd.github.v3+json",
              "Content-Type": "application/json"
            },
            body: JSON.stringify({
              ref: "refs/heads/main",
              sha: commitSha
            })
          });
          if (refResponse.status !== 201) {
            logger10.error("Failed to create main branch");
            return false;
          }
          logger10.success("Created main branch with initial commit");
          baseResponse = await fetch(
            `${GITHUB_API_URL}/repos/${owner}/${repo}/git/ref/heads/main`,
            {
              headers: {
                Authorization: `token ${token}`,
                Accept: "application/vnd.github.v3+json"
              }
            }
          );
        }
      }
    }
    if (baseResponse.status !== 200) {
      logger10.error(`Failed to get base branch ${baseBranch}: ${baseResponse.statusText}`);
      return false;
    }
    const baseData = await baseResponse.json();
    const sha = baseData.object.sha;
    const response = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/git/refs`, {
      method: "POST",
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        ref: `refs/heads/${branch}`,
        sha
      })
    });
    if (response.status === 201) {
      logger10.success(`Created branch ${branch} in ${owner}/${repo}`);
      return true;
    }
    logger10.error(`Failed to create branch: ${response.statusText}`);
    return false;
  } catch (error) {
    logger10.error(
      `Failed to create branch: ${error instanceof Error ? error.message : String(error)}`
    );
    return false;
  }
}
async function getFileContent(token, owner, repo, path19, branch = "main") {
  try {
    const response = await fetch(
      `${GITHUB_API_URL}/repos/${owner}/${repo}/contents/${path19}?ref=${branch}`,
      {
        headers: {
          Authorization: `token ${token}`,
          Accept: "application/vnd.github.v3+json"
        }
      }
    );
    if (response.status === 200) {
      const data = await response.json();
      return Buffer.from(data.content, "base64").toString("utf-8");
    }
    return null;
  } catch (error) {
    return null;
  }
}
async function updateFile(token, owner, repo, path19, content, message, branch = "main") {
  try {
    const existingContent = await getFileContent(token, owner, repo, path19, branch);
    const method = "PUT";
    let sha;
    if (existingContent !== null) {
      const response2 = await fetch(
        `${GITHUB_API_URL}/repos/${owner}/${repo}/contents/${path19}?ref=${branch}`,
        {
          headers: {
            Authorization: `token ${token}`,
            Accept: "application/vnd.github.v3+json"
          }
        }
      );
      if (response2.status === 200) {
        const data = await response2.json();
        sha = data.sha;
      }
    }
    const fileUrl = `${GITHUB_API_URL}/repos/${owner}/${repo}/contents/${path19}`;
    logger10.info(`Updating file at: ${fileUrl}`);
    const requestBody = {
      message,
      content: Buffer.from(content).toString("base64"),
      branch,
      sha
    };
    logger10.info(`Request details: method=${method}, branch=${branch}, has_sha=${!!sha}`);
    const response = await fetch(fileUrl, {
      method,
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json",
        "Content-Type": "application/json"
      },
      body: JSON.stringify(requestBody)
    });
    if (response.status === 200 || response.status === 201) {
      logger10.success(existingContent !== null ? "File updated" : "File created");
      return true;
    }
    const errorBody = await response.text();
    logger10.error(`Failed to update file: ${response.status} ${response.statusText}`);
    logger10.error(`Response body: ${errorBody}`);
    if (response.status === 404) {
      logger10.error(`Repository or path not found: ${owner}/${repo}/${path19}`);
      const repoCheck = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}`, {
        headers: {
          Authorization: `token ${token}`,
          Accept: "application/vnd.github.v3+json"
        }
      });
      if (repoCheck.status === 404) {
        logger10.error(`Repository ${owner}/${repo} does not exist or is not accessible`);
      } else {
        logger10.info(`Repository exists, but path is likely invalid`);
      }
    }
    return false;
  } catch (error) {
    logger10.error(`Error updating file: ${error instanceof Error ? error.message : String(error)}`);
    return false;
  }
}
async function createPullRequest(token, owner, repo, title, body, head, base = "main") {
  try {
    const response = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/pulls`, {
      method: "POST",
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        title,
        body,
        head,
        base
      })
    });
    if (response.status === 201) {
      const data = await response.json();
      logger10.success(`Created pull request: ${data.html_url}`);
      return data.html_url;
    }
    logger10.error(`Failed to create pull request: ${response.statusText}`);
    return null;
  } catch (error) {
    logger10.error(
      `Failed to create pull request: ${error instanceof Error ? error.message : String(error)}`
    );
    return null;
  }
}
async function getAuthenticatedUser(token) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/user`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    if (response.status === 200) {
      return await response.json();
    }
    return null;
  } catch (error) {
    return null;
  }
}
async function getGitHubCredentials() {
  const envInfo = await UserEnvironment.getInstanceInfo();
  logger10.debug("[GitHub] Checking for credentials");
  const envUsername = envInfo.env.GITHUB_USERNAME;
  const envToken = envInfo.env.GITHUB_TOKEN;
  if (envUsername && envToken) {
    if (await validateGitHubToken(envToken)) {
      return {
        username: envUsername,
        token: envToken
      };
    }
    logger10.warn("Invalid GitHub token found in environment variables");
  }
  const { getGitHubToken: getGitHubToken2 } = await import("./registry-3YA2T6KV.js");
  const token = await getGitHubToken2() || void 0;
  if (token) {
    const isValid2 = await validateGitHubToken(token);
    if (isValid2) {
      const userInfo = await getAuthenticatedUser(token);
      if (userInfo) {
        const username = userInfo.login;
        await saveGitHubCredentials(username, token);
        return { username, token };
      }
    } else {
      logger10.warn("Stored GitHub token is invalid, will prompt for new credentials");
    }
  }
  clack4.intro("\u{1F510} GitHub Authentication Required");
  clack4.note(
    `To create a GitHub Personal Access Token (Classic):
1. Go to https://github.com/settings/tokens/new
2. Give your token a descriptive name (e.g., "ElizaOS CLI")
3. Select "No expiration" or any expiration date
4. Select the following scopes (all are required):
   - repo (Full control of private repositories)
   - read:org (Read org and team membership, read org projects)
   - workflow (Update GitHub Action workflows)
5. Click "Generate token" at the bottom of the page
6. Copy the displayed token (you won't be able to see it again!)

NOTE: You must use a Classic token, not a Fine-grained token`,
    "Setup Instructions"
  );
  const promptedUsername = await clack4.text({
    message: "Enter your GitHub username:",
    validate: (value) => value ? void 0 : "Username is required"
  });
  if (clack4.isCancel(promptedUsername)) {
    clack4.cancel("Operation cancelled.");
    return null;
  }
  const promptedToken = await clack4.password({
    message: "Enter your GitHub Personal Access Token (with repo, read:org, and workflow scopes):",
    validate: (value) => value ? void 0 : "Token is required"
  });
  if (clack4.isCancel(promptedToken)) {
    clack4.cancel("Operation cancelled.");
    return null;
  }
  const isValid = await validateGitHubToken(promptedToken);
  if (!isValid) {
    logger10.error("Invalid GitHub token");
    return null;
  }
  await saveGitHubCredentials(promptedUsername, promptedToken);
  logger10.success("GitHub credentials saved successfully");
  return { username: promptedUsername, token: promptedToken };
}
async function saveGitHubCredentials(username, token) {
  const envInfo = await UserEnvironment.getInstanceInfo();
  const { elizaDir, envFilePath } = envInfo.paths;
  logger10.debug("[GitHub] Saving credentials");
  if (!existsSync8(elizaDir)) {
    await fs8.mkdir(elizaDir, { recursive: true });
  }
  if (!existsSync8(envFilePath)) {
    await fs8.writeFile(envFilePath, "", { encoding: "utf8" });
  }
  const currentContent = await fs8.readFile(envFilePath, "utf8");
  const lines = currentContent.split("\n");
  const usernameLineIndex = lines.findIndex((line) => line.startsWith("GITHUB_USERNAME="));
  const usernameLine = `GITHUB_USERNAME=${username}`;
  if (usernameLineIndex >= 0) {
    lines[usernameLineIndex] = usernameLine;
  } else {
    lines.push(usernameLine);
  }
  const tokenLineIndex = lines.findIndex((line) => line.startsWith("GITHUB_TOKEN="));
  const tokenLine = `GITHUB_TOKEN=${token}`;
  if (tokenLineIndex >= 0) {
    lines[tokenLineIndex] = tokenLine;
  } else {
    lines.push(tokenLine);
  }
  await fs8.writeFile(envFilePath, lines.join("\n"));
  process.env.GITHUB_USERNAME = username;
  process.env.GITHUB_TOKEN = token;
  logger10.success("GitHub credentials saved");
}
async function ensureDirectory(token, repo, path19, branch) {
  try {
    try {
      const response = await fetch(
        `${GITHUB_API_URL}/repos/${repo}/contents/${path19}?ref=${branch}`,
        {
          headers: {
            Authorization: `token ${token}`,
            Accept: "application/vnd.github.v3+json"
          }
        }
      );
      if (response.status === 200) {
        logger10.info(`Directory ${path19} already exists`);
        return true;
      }
    } catch (error) {
      logger10.info(`Directory ${path19} doesn't exist, creating it`);
    }
    const placeholderPath = `${path19}/.gitkeep`;
    const result = await updateFile(
      token,
      repo,
      placeholderPath,
      "",
      // Empty content for placeholder
      `Create directory: ${path19}`,
      branch
    );
    if (result) {
      logger10.success(`Created directory: ${path19}`);
      return true;
    }
    logger10.error(`Failed to create directory: ${path19}`);
    return false;
  } catch (error) {
    logger10.error(
      `Error creating directory: ${error instanceof Error ? error.message : String(error)}`
    );
    return false;
  }
}
async function createGitHubRepository(token, repoName, description, isPrivate = false, topics = []) {
  try {
    const userResponse = await fetch(`${GITHUB_API_URL}/user`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    if (userResponse.status !== 200) {
      return { success: false, message: "Failed to get authenticated user information" };
    }
    const userData = await userResponse.json();
    const username = userData.login;
    const checkResponse = await fetch(`${GITHUB_API_URL}/repos/${username}/${repoName}`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    if (checkResponse.status === 200) {
      const data = await checkResponse.json();
      logger10.info(`Repository already exists: ${data.html_url}`);
      return { success: true, repoUrl: data.html_url };
    }
    if (checkResponse.status !== 404) {
      const errorData2 = await checkResponse.json();
      return {
        success: false,
        message: `Error checking repository: ${checkResponse.status} ${checkResponse.statusText} - ${errorData2.message || "Unknown error"}`
      };
    }
    const response = await fetch(`${GITHUB_API_URL}/user/repos`, {
      method: "POST",
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        name: repoName,
        description,
        private: isPrivate,
        has_issues: true,
        has_projects: false,
        has_wiki: false,
        auto_init: false,
        // Don't initialize with README to avoid conflicts
        default_branch: "main"
        // Explicitly set main as default branch
      })
    });
    if (response.status === 201) {
      const data = await response.json();
      const repoUrl = data.html_url;
      await new Promise((resolve2) => setTimeout(resolve2, 1e3));
      if (topics.length > 0) {
        await fetch(`${GITHUB_API_URL}/repos/${data.full_name}/topics`, {
          method: "PUT",
          headers: {
            Authorization: `token ${token}`,
            Accept: "application/vnd.github.mercy-preview+json",
            // Required for topics API
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            names: topics
          })
        });
      }
      logger10.success(`Repository created: ${repoUrl}`);
      return { success: true, repoUrl };
    }
    const errorData = await response.json();
    return {
      success: false,
      message: `Failed to create repository: ${response.status} ${response.statusText} - ${errorData.message || "Unknown error"}`
    };
  } catch (error) {
    return {
      success: false,
      message: `Error creating repository: ${error instanceof Error ? error.message : String(error)}`
    };
  }
}
async function pushToGitHub(cwd, repoUrl, branch = "main") {
  try {
    const gitDirExists = existsSync8(path10.join(cwd, ".git"));
    let hasCorrectRemote = false;
    if (gitDirExists) {
      try {
        const { stdout: remoteUrl } = await execa5("git", ["remote", "get-url", "origin"], { cwd });
        const sanitizedRepoUrl = repoUrl.replace(/https:\/\/.*?@/, "https://");
        const sanitizedRemoteUrl = remoteUrl.replace(/https:\/\/.*?@/, "https://");
        hasCorrectRemote = sanitizedRemoteUrl.includes(
          sanitizedRepoUrl.replace(/^https:\/\/.*?@/, "")
        );
      } catch (error) {
        hasCorrectRemote = false;
      }
    }
    if (!gitDirExists || !hasCorrectRemote) {
      if (gitDirExists) {
        logger10.info("Existing git repository has incorrect remote, reinitializing...");
        await execa5("rm", ["-rf", ".git"], { cwd });
      }
      await execa5("git", ["init"], { cwd });
      await execa5("git", ["checkout", "-b", "main"], { cwd });
      logger10.info("Git repository initialized with main branch");
      await execa5("git", ["remote", "add", "origin", repoUrl], { cwd });
      logger10.info(`Added remote: ${repoUrl.replace(/\/\/.*?@/, "//***@")}`);
    } else {
      try {
        await execa5("git", ["rev-parse", "--verify", branch], { cwd });
        await execa5("git", ["checkout", branch], { cwd });
      } catch (error) {
        await execa5("git", ["checkout", "-b", branch], { cwd });
        logger10.info(`Created and switched to ${branch} branch`);
      }
    }
    await execa5("git", ["add", "."], { cwd });
    logger10.info("Added files to git");
    try {
      await execa5("git", ["config", "user.email"], { cwd });
    } catch (error) {
      await execa5("git", ["config", "user.email", "plugindev@elizaos.com"], { cwd });
      await execa5("git", ["config", "user.name", "ElizaOS Plugin Dev"], { cwd });
      logger10.info("Set git user info for commit");
    }
    try {
      await execa5("git", ["commit", "-m", "Initial commit from ElizaOS CLI"], { cwd });
      logger10.info("Committed changes");
    } catch (error) {
      logger10.info("No changes to commit");
    }
    try {
      await execa5("git", ["push", "-u", "origin", branch], { cwd });
      logger10.success(`Pushed to GitHub repository: ${repoUrl}`);
      return true;
    } catch (error) {
      logger10.error(
        `Failed to push to GitHub: ${error instanceof Error ? error.message : String(error)}`
      );
      try {
        logger10.info("Attempting force push...");
        await execa5("git", ["push", "-u", "origin", "main", "--force-with-lease"], {
          cwd,
          stdio: "pipe"
        });
        return true;
      } catch (forcePushError) {
        logger10.error(
          "Force push also failed:",
          forcePushError instanceof Error ? forcePushError.message : String(forcePushError)
        );
        return false;
      }
    }
  } catch (error) {
    logger10.error(
      `Error in git operations: ${error instanceof Error ? error.message : String(error)}`
    );
    return false;
  }
}

// src/utils/handle-error.ts
import { logger as logger13 } from "@elizaos/core";

// src/commands/agent/index.ts
import { Command } from "commander";

// src/commands/agent/actions/crud.ts
import { logger as logger11 } from "@elizaos/core";
import { writeFileSync, readFileSync as readFileSync5 } from "fs";
import path11 from "path";

// src/commands/agent/utils/validation.ts
import { z as z2 } from "zod";
var AgentBasicSchema = z2.object({
  id: z2.string(),
  name: z2.string(),
  status: z2.string().optional()
}).passthrough();
var AgentsListResponseSchema = z2.object({
  success: z2.boolean(),
  data: z2.object({
    agents: z2.array(AgentBasicSchema)
  }).optional()
});
async function getAgents(opts) {
  const baseUrl = getAgentsBaseUrl(opts);
  const response = await fetch(baseUrl);
  if (!response.ok) {
    throw new Error(`Failed to fetch agents list: ${response.statusText}`);
  }
  const rawData = await response.json();
  const validatedData = AgentsListResponseSchema.parse(rawData);
  return validatedData.data?.agents || [];
}
async function resolveAgentId(idOrNameOrIndex, opts) {
  const agents = await getAgents(opts);
  const agentByName = agents.find(
    (agent2) => agent2.name.toLowerCase() === idOrNameOrIndex.toLowerCase()
  );
  if (agentByName) {
    return agentByName.id;
  }
  const agentById = agents.find((agent2) => agent2.id === idOrNameOrIndex);
  if (agentById) {
    return agentById.id;
  }
  if (!Number.isNaN(Number(idOrNameOrIndex))) {
    const indexAgent = agents[Number(idOrNameOrIndex)];
    if (indexAgent) {
      return indexAgent.id;
    }
  }
  throw new Error(`AGENT_NOT_FOUND:${idOrNameOrIndex}`);
}

// src/commands/agent/utils/display.ts
async function listAgents(opts) {
  try {
    const agents = await getAgents(opts);
    const agentData = agents.map((agent2) => ({
      Name: agent2.name,
      ID: agent2.id,
      Status: agent2.status || "unknown"
    }));
    if (opts.json) {
      console.info(JSON.stringify(agentData, null, 2));
    } else {
      console.info("\nAvailable agents:");
      if (agentData.length === 0) {
        console.info("No agents found");
      } else {
        console.table(agentData);
      }
    }
    return;
  } catch (error) {
    await checkServer(opts);
    handleError(error);
  }
}

// src/commands/agent/actions/crud.ts
async function safeJsonParse(response) {
  try {
    return await response.json();
  } catch (error) {
    console.error("Failed to parse response as JSON:", error);
    return null;
  }
}
async function handleErrorResponse(response, defaultMessage) {
  const errorData = await safeJsonParse(response);
  throw new Error(errorData?.error?.message || defaultMessage);
}
async function getAgent(opts) {
  try {
    const resolvedAgentId = await resolveAgentId(opts.name, opts);
    const baseUrl = getAgentsBaseUrl(opts);
    console.info(`Getting agent ${resolvedAgentId}`);
    const response = await fetch(`${baseUrl}/${resolvedAgentId}`);
    if (!response.ok) {
      logger11.error(`Failed to get agent`);
      process.exit(1);
    }
    const responseData = await safeJsonParse(response);
    if (!responseData) {
      throw new Error("Failed to parse agent data from server response");
    }
    const agent2 = responseData.data;
    if (!agent2) {
      throw new Error("No agent data received from server");
    }
    if (opts.output !== void 0) {
      const { id, createdAt, updatedAt, enabled, ...agentConfig } = agent2;
      const filename = opts.output === true ? `${agent2.name || "agent"}.json` : `${String(opts.output)}${String(opts.output).endsWith(".json") ? "" : ".json"}`;
      const jsonPath = path11.resolve(process.cwd(), filename);
      writeFileSync(jsonPath, JSON.stringify(agentConfig, null, 2));
      console.log(`Saved agent configuration to ${jsonPath}`);
      return;
    }
    displayAgent(agent2, "Agent Details");
    if (opts.json) {
      const { id, createdAt, updatedAt, enabled, ...agentConfig } = agent2;
      console.log(JSON.stringify(agentConfig, null, 2));
    }
    return;
  } catch (error) {
    await checkServer(opts);
    handleError(error);
  }
}
async function removeAgent(opts) {
  try {
    const resolvedAgentId = await resolveAgentId(opts.name, opts);
    const baseUrl = getAgentsBaseUrl(opts);
    console.info(`Removing agent ${resolvedAgentId}`);
    const response = await fetch(`${baseUrl}/${resolvedAgentId}`, {
      method: "DELETE"
    });
    if (!response.ok) {
      await handleErrorResponse(response, `Failed to remove agent: ${response.statusText}`);
    }
    console.log(`Successfully removed agent ${opts.name}`);
    return;
  } catch (error) {
    await checkServer(opts);
    handleError(error);
  }
}
async function clearAgentMemories(opts) {
  try {
    const resolvedAgentId = await resolveAgentId(opts.name, opts);
    const baseUrl = getAgentsBaseUrl(opts);
    console.info(`Clearing all memories for agent ${resolvedAgentId}`);
    const response = await fetch(`${baseUrl}/${resolvedAgentId}/memories`, {
      method: "DELETE"
    });
    if (!response.ok) {
      await handleErrorResponse(response, `Failed to clear agent memories: ${response.statusText}`);
    }
    const data = await safeJsonParse(response);
    const result = data?.data || null;
    console.log(
      `Successfully cleared ${result?.deletedCount || 0} memories for agent ${opts.name}`
    );
    return;
  } catch (error) {
    await checkServer(opts);
    handleError(error);
  }
}
async function setAgentConfig(opts) {
  try {
    const resolvedAgentId = await resolveAgentId(opts.name, opts);
    console.info(`Updating configuration for agent ${resolvedAgentId}`);
    let config;
    if (opts.config) {
      try {
        config = JSON.parse(opts.config);
      } catch (error) {
        throw new Error(
          `Failed to parse config JSON string: ${error instanceof Error ? error.message : String(error)}`
        );
      }
    } else if (opts.file) {
      try {
        config = JSON.parse(readFileSync5(opts.file, "utf8"));
      } catch (error) {
        throw new Error(
          `Failed to read or parse config file: ${error instanceof Error ? error.message : String(error)}`
        );
      }
    } else {
      throw new Error("Please provide either a config JSON string (-c) or a config file path (-f)");
    }
    const response = await fetch(`${getAgentsBaseUrl(opts)}/${resolvedAgentId}`, {
      method: "PATCH",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(config)
    });
    if (!response.ok) {
      await handleErrorResponse(
        response,
        `Failed to update agent configuration: ${response.statusText}`
      );
    }
    const data = await safeJsonParse(response);
    const result = data?.data || null;
    console.log(`Successfully updated configuration for agent ${result?.id || resolvedAgentId}`);
  } catch (error) {
    await checkServer(opts);
    handleError(error);
  }
}

// src/commands/agent/actions/lifecycle.ts
import { logger as logger12 } from "@elizaos/core";
import { existsSync as existsSync9, readFileSync as readFileSync6 } from "fs";
import path12 from "path";
async function startAgent(options) {
  try {
    const hasValidInput = options.path || options.remoteCharacter || options.name && options.name !== true && options.name !== "";
    if (!hasValidInput) {
      console.error("\nError: No character configuration provided.");
      try {
        const agents = await getAgents(options);
        if (agents.length > 0) {
          console.error("\nAvailable agents in your project:");
          agents.forEach((agent2, index) => {
            console.error(`  ${index}. ${agent2.name}`);
          });
        }
      } catch (error) {
        await checkServer(options);
        handleError(error);
      }
      throw new Error("MISSING_CHARACTER_CONFIG");
    }
    const response = await (async () => {
      const payload = {};
      const headers = { "Content-Type": "application/json" };
      const baseUrl = getAgentsBaseUrl(options);
      let characterName = null;
      async function createCharacter(payload2) {
        const response2 = await fetch(baseUrl, {
          method: "POST",
          headers,
          body: JSON.stringify(payload2)
        });
        if (!response2.ok) {
          const errorText = await response2.text();
          logger12.error(`Server returned ${response2.status}: ${errorText}`);
          return null;
        }
        const data2 = await response2.json();
        if (!data2?.data?.character?.name) {
          logger12.error(`Unexpected response format:`, data2);
          return null;
        }
        return data2.data.character.name;
      }
      if (options.path) {
        try {
          const filePath = path12.resolve(process.cwd(), options.path);
          if (!existsSync9(filePath)) {
            throw new Error(`File not found at path: ${filePath}`);
          }
          const fileContent = readFileSync6(filePath, "utf8");
          payload.characterJson = JSON.parse(fileContent);
          characterName = await createCharacter(payload);
          if (!characterName) {
            logger12.error("Failed to create character from file. Check server logs for details.");
          }
        } catch (error) {
          console.error("Error reading or parsing local JSON file:", error);
          throw new Error(
            `Failed to read or parse local JSON file: ${error instanceof Error ? error.message : String(error)}`
          );
        }
      }
      if (options.remoteCharacter) {
        if (!options.remoteCharacter.startsWith("http://") && !options.remoteCharacter.startsWith("https://")) {
          console.error("Invalid remote URL:", options.remoteCharacter);
          throw new Error("Remote URL must start with http:// or https://");
        }
        payload.characterPath = options.remoteCharacter;
        characterName = await createCharacter(payload);
        if (!characterName) {
          logger12.error(
            "Failed to create character from remote URL. Check server logs for details."
          );
        }
      }
      if (options.name) {
        characterName = options.name;
      }
      if (characterName) {
        try {
          const agentId = await resolveAgentId(characterName, options);
          return await fetch(`${baseUrl}/${agentId}/start`, {
            method: "POST",
            headers
          });
        } catch (error) {
          throw error;
        }
      }
      return await fetch(baseUrl, {
        method: "POST",
        headers,
        body: JSON.stringify({})
        // Empty body for default agent start
      });
    })();
    if (!response.ok) {
      let errorData = null;
      try {
        errorData = await response.json();
      } catch (jsonError) {
        console.error("Failed to parse error response as JSON:", jsonError);
        throw new Error(`Failed to start agent: ${response.statusText}`);
      }
      throw new Error(errorData?.error?.message || `Failed to start agent: ${response.statusText}`);
    }
    const data = await response.json();
    const result = data.data;
    if (!result) {
      console.error("Server responded OK, but no agent data was returned");
      throw new Error("Failed to start agent: No data returned from server");
    }
    const agentName = result.name || result?.character?.name || "unknown";
    console.log(`\x1B[32m[\u2713] Agent ${agentName} started successfully!\x1B[0m`);
  } catch (error) {
    if (error instanceof Error) {
      const errorMsg = error.message;
      if (errorMsg.startsWith("AGENT_NOT_FOUND:")) {
        const agentName = errorMsg.split(":")[1];
        console.error(`
Error: No agent found with name "${agentName}"`);
        try {
          const agents = await getAgents(options);
          if (agents.length > 0) {
            console.error("\nAvailable agents in your project:");
            agents.forEach((agent2, index) => {
              console.error(`  ${index}. ${agent2.name}`);
            });
            console.error(
              `
You can create a new agent with: elizaos create -t agent ${agentName.toLowerCase()}`
            );
          }
        } catch (error2) {
        }
        throw new Error("AGENT_NOT_FOUND_WITH_HELP");
      } else if (errorMsg === "MISSING_CHARACTER_CONFIG") {
        throw new Error("MISSING_CHARACTER_CONFIG");
      } else {
        await checkServer(options);
        handleError(error);
      }
    } else {
      await checkServer(options);
      handleError(error);
    }
    process.exit(1);
  }
}
async function stopAgent(opts) {
  try {
    const hasValidName = opts.name && opts.name !== true && opts.name !== "";
    if (!hasValidName && !opts.all) {
      console.error("\nError: Must provide either --name <name> or --all flag");
      console.error("Examples:");
      console.error("  elizaos agent stop --name eliza");
      console.error("  elizaos agent stop --all");
      process.exit(1);
    }
    if (opts.all) {
      logger12.info("Stopping all ElizaOS agents...");
      if (process.platform === "win32") {
        logger12.error("The --all flag requires Unix-like commands (pgrep, kill).");
        logger12.error("On Windows, please use WSL 2 or stop agents individually with --name.");
        logger12.error("See: https://learn.microsoft.com/en-us/windows/wsl/install-manual");
        process.exit(1);
      }
      try {
        const { exec } = await import("child_process");
        const { promisify } = await import("util");
        const execAsync = promisify(exec);
        const patterns = [
          "(node|bun).*elizaos",
          "(node|bun).*eliza.*start",
          "(node|bun).*dist/index.js.*start"
        ];
        for (const pattern of patterns) {
          try {
            const { stdout } = await execAsync(`pgrep -f "${pattern}"`);
            const pids = stdout.trim().split("\n").filter((pid) => pid && pid !== process.pid.toString());
            if (pids.length > 0) {
              await execAsync(`echo "${pids.join(" ")}" | xargs -r kill`);
            }
          } catch (pgrepError) {
          }
        }
        logger12.success("All ElizaOS agents stopped successfully!");
      } catch (error) {
        logger12.error(
          `Error stopping processes: ${error instanceof Error ? error.message : String(error)}`
        );
        process.exit(1);
      }
      return;
    }
    const resolvedAgentId = await resolveAgentId(opts.name, opts);
    const baseUrl = getAgentsBaseUrl(opts);
    console.info(`Stopping agent ${resolvedAgentId}`);
    const response = await fetch(`${baseUrl}/${resolvedAgentId}/stop`, { method: "POST" });
    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(errorData.error?.message || `Failed to stop agent: ${response.statusText}`);
    }
    logger12.success(`Successfully stopped agent ${opts.name}`);
    console.log(`Agent ${opts.name} stopped successfully!`);
  } catch (error) {
    await checkServer(opts);
    handleError(error);
  }
}

// src/commands/agent/index.ts
var agent = new Command().name("agent").description("Manage ElizaOS agents");
agent.command("list").alias("ls").description("List available agents").option("-j, --json", "output as JSON").option("-r, --remote-url <url>", "URL of the remote agent runtime").option("-p, --port <port>", "Port to listen on", (val) => Number.parseInt(val)).action(listAgents);
agent.command("get").alias("g").description("Get agent details").requiredOption("-n, --name <name>", "agent id, name, or index number from list").option("-j, --json", "display agent configuration as JSON in the console").option("-o, --output [file]", "save agent config to JSON (defaults to {name}.json)").option("-r, --remote-url <url>", "URL of the remote agent runtime").option("-p, --port <port>", "Port to listen on", (val) => Number.parseInt(val)).action(getAgent);
agent.command("start").alias("s").description("Start an agent with a character profile").option("-n, --name <name>", "Name of an existing agent to start").option("--path <path>", "Path to local character JSON file").option("--remote-character <url>", "URL to remote character JSON file").option("-r, --remote-url <url>", "URL of the remote agent runtime").option("-p, --port <port>", "Port to listen on", (val) => Number.parseInt(val)).addHelpText(
  "after",
  `
Examples:
  $ elizaos agent start -n "Agent Name"     Start an existing agent by name
  $ elizaos agent start --path ./char.json  Start with a local character file
  $ elizaos agent start --remote-character https://example.com/char.json

To create a new agent:
  $ elizaos create -t agent my-agent-name   Create a new agent using Eliza template

Required configuration:
  You must provide one of these options: --name, --path, or --remote-character
`
).action(async (options) => {
  try {
    await startAgent(options);
  } catch (error) {
    if (error instanceof Error) {
      const errorMsg = error.message;
      if (errorMsg === "MISSING_CHARACTER_CONFIG") {
        const cmd = agent.commands.find((cmd2) => cmd2.name() === "start");
        cmd?.help();
        process.exit(1);
      } else if (errorMsg === "AGENT_NOT_FOUND_WITH_HELP") {
        const cmd = agent.commands.find((cmd2) => cmd2.name() === "start");
        cmd?.help();
        process.exit(1);
      }
    }
    throw error;
  }
});
agent.command("stop").alias("st").description("Stop an agent").option("-n, --name <name>", "agent id, name, or index number from list").option("--all", "stop all running agents").option("-r, --remote-url <url>", "URL of the remote agent runtime").option("-p, --port <port>", "Port to listen on", (val) => Number.parseInt(val)).action(stopAgent);
agent.command("remove").alias("rm").description("Remove an agent").requiredOption("-n, --name <name>", "agent id, name, or index number from list").option("-r, --remote-url <url>", "URL of the remote agent runtime").option("-p, --port <port>", "Port to listen on", (val) => Number.parseInt(val)).action(removeAgent);
agent.command("set").description("Update agent configuration").requiredOption("-n, --name <name>", "agent id, name, or index number from list").option("-c, --config <json>", "agent configuration as JSON string").option("-f, --file <path>", "path to agent configuration JSON file").option("-r, --remote-url <url>", "URL of the remote agent runtime").option("-p, --port <port>", "Port to listen on", (val) => Number.parseInt(val)).action(setAgentConfig);
agent.command("clear-memories").alias("clear").description("Clear all memories for an agent").requiredOption("-n, --name <name>", "agent id, name, or index number from list").option("-r, --remote-url <url>", "URL of the remote agent runtime").option("-p, --port <port>", "Port to listen on", (val) => Number.parseInt(val)).action(clearAgentMemories);

// src/utils/handle-error.ts
import colors2 from "yoctocolors";
function handleError(error) {
  const isNoSpace = error instanceof Error && (error.message.includes("no space left on device") || error.message.includes("ENOSPC")) || typeof error === "string" && (error.includes("no space left on device") || error.includes("ENOSPC"));
  if (isNoSpace) {
    logger13.error(
      colors2.red("ERROR: No space left on device! Please free up disk space and try again.")
    );
    if (error instanceof Error) {
      logger13.error(colors2.red(error.message));
      logger13.error(colors2.red(error.stack || ""));
    } else {
      logger13.error(colors2.red(String(error)));
    }
  } else {
    logger13.error("An error occurred:", error);
    if (error instanceof Error) {
      logger13.error("Error details:", error.message);
      logger13.error("Stack trace:", error.stack);
    } else {
      logger13.error("Unknown error type:", typeof error);
      logger13.error("Error value:", error);
    }
  }
  process.exit(1);
}
async function checkServer(opts) {
  try {
    const response = await fetch(`${getAgentRuntimeUrl(opts)}/api/agents`);
    if (!response.ok) {
      throw new Error(`Server responded with ${response.status}: ${response.statusText}`);
    }
    logger13.success("ElizaOS server is running");
  } catch (error) {
    logger13.error("Unable to connect to ElizaOS server, likely not running or not accessible!");
    process.exit(1);
  }
}

// src/utils/helpers.ts
import colors3 from "yoctocolors";
function displayAgent(data, title = "Agent Review") {
  logHeader(title);
  console.log(`Name: ${data.name}`);
  console.log(`Username: ${data.username || data.name?.toLowerCase().replace(/\s+/g, "_")}`);
  displaySection("Bio", Array.isArray(data.bio) ? data.bio : data.bio ? [data.bio] : void 0);
  displaySection("Adjectives", data.adjectives);
  displaySection("Topics", data.topics);
  displaySection("Plugins", data.plugins);
  if (data.style) {
    displaySection("General Style", data.style.all);
    displaySection("Chat Style", data.style.chat);
    displaySection("Post Style", data.style.post);
  }
  displaySection("Post Examples", data.postExamples);
  if (data.messageExamples && data.messageExamples.length > 0) {
    console.log(`
${colors3.cyan("Message Examples:")}`);
    console.log(
      data.messageExamples.map((conversation, i) => {
        const messages = formatConversation(conversation);
        return `
Conversation ${i + 1}:
${messages}`;
      }).join("\n")
    );
  }
}
function formatConversation(conversation) {
  return conversation.map((msg) => {
    const user = msg.name === "{{name1}}" ? "Anon" : msg.name;
    return `${user}: ${msg.content.text}`;
  }).join("\n");
}
function displaySection(title, items) {
  if (!items || items.length === 0) return;
  console.log(`
${colors3.cyan(`${title}:`)}`);
  for (const item of items) {
    console.log(`  ${item}`);
  }
}
function logHeader(title) {
  const padding = 2;
  const titleStr = `=== ${title} ===`;
  const paddedTitle = " ".repeat(padding) + titleStr + " ".repeat(padding);
  const borderLength = paddedTitle.length;
  const topBorder = colors3.green(`\u250C${"\u2500".repeat(borderLength)}\u2510`);
  const bottomBorder = colors3.green(`\u2514${"\u2500".repeat(borderLength)}\u2518`);
  const coloredTitle = `${" ".repeat(padding)}=== ${colors3.green(title)} ===${" ".repeat(padding)}`;
  const middleRow = colors3.green("\u2502") + coloredTitle + colors3.green("\u2502");
  console.log(`
${topBorder}
${middleRow}
${bottomBorder}`);
}

// src/utils/install-plugin.ts
import { logger as logger18 } from "@elizaos/core";
import { existsSync as existsSync13 } from "fs";
import path16 from "path";

// src/utils/load-plugin.ts
import { logger as logger15 } from "@elizaos/core";
import { existsSync as existsSync11, readFileSync as readFileSync8 } from "fs";
import path14 from "path";

// src/utils/plugin-context.ts
import { logger as logger14 } from "@elizaos/core";
import { existsSync as existsSync10, readFileSync as readFileSync7 } from "fs";
import path13 from "path";
function normalizeForComparison(name) {
  const normalized = normalizePluginName(name)[0] || name;
  return normalized.toLowerCase();
}
function detectPluginContext(pluginName) {
  const cwd = process.cwd();
  const directoryInfo = detectDirectoryType(cwd);
  if (directoryInfo.type !== "elizaos-plugin" || !directoryInfo.hasPackageJson) {
    return { isLocalDevelopment: false };
  }
  const packageJsonPath = path13.join(cwd, "package.json");
  let packageInfo;
  try {
    packageInfo = JSON.parse(readFileSync7(packageJsonPath, "utf-8"));
  } catch (error) {
    logger14.debug(`Failed to parse package.json: ${error}`);
    return { isLocalDevelopment: false };
  }
  const normalizedRequestedPlugin = normalizeForComparison(pluginName);
  const normalizedCurrentPackage = normalizeForComparison(packageInfo.name);
  const dirName = path13.basename(cwd);
  const normalizedDirName = normalizeForComparison(dirName);
  const isCurrentPlugin = normalizedRequestedPlugin === normalizedCurrentPackage || normalizedRequestedPlugin === normalizedDirName;
  if (isCurrentPlugin) {
    const mainEntry = packageInfo.main || "dist/index.js";
    const localPath = path13.resolve(cwd, mainEntry);
    const needsBuild = !existsSync10(localPath);
    logger14.debug(`Detected local plugin development: ${pluginName}`);
    logger14.debug(`Expected output: ${localPath}`);
    logger14.debug(`Needs build: ${needsBuild}`);
    return {
      isLocalDevelopment: true,
      localPath,
      packageInfo,
      needsBuild
    };
  }
  return { isLocalDevelopment: false };
}
async function ensurePluginBuilt(context) {
  if (!context.isLocalDevelopment || !context.needsBuild || !context.packageInfo) {
    return true;
  }
  const { packageInfo, localPath } = context;
  if (packageInfo.scripts?.build) {
    logger14.info("Plugin not built, attempting to build...");
    try {
      await buildProject(process.cwd(), true);
      if (localPath && existsSync10(localPath)) {
        logger14.success("Plugin built successfully");
        return true;
      } else {
        logger14.error(`Build completed but expected output not found: ${localPath}`);
        return false;
      }
    } catch (error) {
      logger14.error(`Build failed: ${error}`);
      return false;
    }
  }
  logger14.error(`Plugin not built and no build script found in package.json`);
  logger14.info(`Add a "build" script to package.json or run 'bun run build' manually`);
  return false;
}
function provideLocalPluginGuidance(pluginName, context) {
  if (!context.isLocalDevelopment) {
    return;
  }
  logger14.info(`
Local plugin development detected for: ${pluginName}`);
  if (context.needsBuild) {
    logger14.info("To fix this issue:");
    logger14.info("1. Build the plugin: bun run build");
    logger14.info("2. Verify the output exists at: " + context.localPath);
    logger14.info("3. Re-run the test command");
  } else {
    logger14.info("Plugin appears to be built but failed to load.");
    logger14.info("Try rebuilding: bun run build");
  }
  logger14.info("\nFor more information, see the plugin development guide.");
}

// src/utils/load-plugin.ts
var DEFAULT_ENTRY_POINT = "dist/index.js";
function getGlobalNodeModulesPath() {
  const nodeDir = path14.dirname(process.execPath);
  if (process.platform === "win32") {
    return path14.join(nodeDir, "node_modules");
  } else {
    return path14.join(nodeDir, "..", "lib", "node_modules");
  }
}
function resolveNodeModulesPath(repository, ...segments) {
  return path14.resolve(process.cwd(), "node_modules", repository, ...segments);
}
async function readPackageJson(repository) {
  const packageJsonPath = resolveNodeModulesPath(repository, "package.json");
  try {
    if (existsSync11(packageJsonPath)) {
      return JSON.parse(readFileSync8(packageJsonPath, "utf-8"));
    }
  } catch (error) {
    logger15.debug(`Failed to read package.json for '${repository}':`, error);
  }
  return null;
}
async function tryImporting(importPath, strategy, repository) {
  try {
    const module = await import(importPath);
    logger15.success(`Successfully loaded plugin '${repository}' using ${strategy} (${importPath})`);
    return module;
  } catch (error) {
    logger15.debug(`Import failed using ${strategy} ('${importPath}'):`, error);
    return null;
  }
}
var importStrategies = [
  // Try local development first - this is the most important for plugin testing
  {
    name: "local development plugin",
    tryImport: async (repository) => {
      const context = detectPluginContext(repository);
      if (context.isLocalDevelopment) {
        logger15.debug(`Detected local development for plugin: ${repository}`);
        const isBuilt = await ensurePluginBuilt(context);
        if (!isBuilt) {
          provideLocalPluginGuidance(repository, context);
          return null;
        }
        if (context.localPath && existsSync11(context.localPath)) {
          logger15.info(`Loading local development plugin: ${repository}`);
          return tryImporting(context.localPath, "local development plugin", repository);
        }
        logger15.warn(`Plugin built but output not found at expected path: ${context.localPath}`);
        provideLocalPluginGuidance(repository, context);
        return null;
      }
      return null;
    }
  },
  // Try workspace dependencies (for monorepo packages)
  {
    name: "workspace dependency",
    tryImport: async (repository) => {
      if (repository.startsWith("@elizaos/plugin-")) {
        const pluginName = repository.replace("@elizaos/", "");
        const workspacePath = path14.resolve(process.cwd(), "..", pluginName, "dist", "index.js");
        if (existsSync11(workspacePath)) {
          return tryImporting(workspacePath, "workspace dependency", repository);
        }
      }
      return null;
    }
  },
  {
    name: "direct path",
    tryImport: async (repository) => tryImporting(repository, "direct path", repository)
  },
  {
    name: "local node_modules",
    tryImport: async (repository) => tryImporting(resolveNodeModulesPath(repository), "local node_modules", repository)
  },
  {
    name: "global node_modules",
    tryImport: async (repository) => {
      const globalPath = path14.resolve(getGlobalNodeModulesPath(), repository);
      if (!existsSync11(path14.dirname(globalPath))) {
        logger15.debug(
          `Global node_modules directory not found at ${path14.dirname(globalPath)}, skipping for ${repository}`
        );
        return null;
      }
      return tryImporting(globalPath, "global node_modules", repository);
    }
  },
  {
    name: "package.json entry",
    tryImport: async (repository) => {
      const packageJson = await readPackageJson(repository);
      if (!packageJson) return null;
      const entryPoint = packageJson.module || packageJson.main || DEFAULT_ENTRY_POINT;
      return tryImporting(
        resolveNodeModulesPath(repository, entryPoint),
        `package.json entry (${entryPoint})`,
        repository
      );
    }
  },
  {
    name: "common dist pattern",
    tryImport: async (repository) => {
      const packageJson = await readPackageJson(repository);
      if (packageJson?.main === DEFAULT_ENTRY_POINT) return null;
      return tryImporting(
        resolveNodeModulesPath(repository, DEFAULT_ENTRY_POINT),
        "common dist pattern",
        repository
      );
    }
  }
];
function isElizaOSPackageName(repository) {
  return repository.startsWith("@elizaos/") || repository.startsWith("@elizaos-plugins/");
}
function getStrategiesForPlugin(repository) {
  const isElizaOS = isElizaOSPackageName(repository);
  if (isElizaOS) {
    return importStrategies;
  } else {
    return importStrategies.filter(
      (strategy) => strategy.name === "local development plugin" || strategy.name === "package.json entry" || strategy.name === "common dist pattern"
    );
  }
}
async function loadPluginModule(repository) {
  const isElizaOS = isElizaOSPackageName(repository);
  const strategies = getStrategiesForPlugin(repository);
  logger15.debug(
    `Loading ${isElizaOS ? "ElizaOS" : "third-party"} plugin: ${repository} (${strategies.length} strategies)`
  );
  for (const strategy of strategies) {
    const result = await strategy.tryImport(repository);
    if (result) return result;
  }
  logger15.warn(`Failed to load plugin module '${repository}' using all relevant strategies.`);
  return null;
}

// src/utils/package-manager.ts
import { logger as logger16 } from "@elizaos/core";
import { existsSync as existsSync12 } from "fs";
import path15 from "path";
import { execa as execa6 } from "execa";
async function getPackageManager() {
  logger16.debug("[PackageManager] Using bun as the package manager for ElizaOS CLI");
  return "bun";
}
async function isGlobalInstallation() {
  const envInfo = await UserEnvironment.getInstanceInfo();
  return envInfo.packageManager.global;
}
async function isRunningViaNpx() {
  const envInfo = await UserEnvironment.getInstanceInfo();
  return envInfo.packageManager.isNpx;
}
async function isRunningViaBunx() {
  const envInfo = await UserEnvironment.getInstanceInfo();
  return envInfo.packageManager.isBunx;
}
function getInstallCommand(isGlobal) {
  return ["add", ...isGlobal ? ["-g"] : []];
}
async function removeFromBunLock(packageName, directory) {
  const lockFilePath = path15.join(directory, "bun.lock");
  if (!existsSync12(lockFilePath)) {
    logger16.debug(`No bun.lock file found at ${lockFilePath}, skipping removal`);
    return;
  }
  try {
    await execa6("bun", ["remove", packageName], {
      cwd: directory,
      stdio: "pipe"
      // Don't show output for cleanup operation
    });
    logger16.debug(`Successfully removed ${packageName} from bun.lock`);
  } catch (error) {
    if (error.message?.includes("not found") || error.message?.includes("No such package")) {
      logger16.debug(`Package ${packageName} not found in lockfile (expected for cleanup)`);
    } else {
      logger16.warn(`Failed to remove ${packageName} from bun.lock: ${error.message}`);
    }
  }
}
async function executeInstallation(packageName, versionOrTag = "", directory = process.cwd()) {
  const installCommand = getInstallCommand(false);
  const finalSpecifier = packageName.startsWith("github:") ? `${packageName}${versionOrTag ? `#${versionOrTag}` : ""}` : versionOrTag ? `${packageName}@${versionOrTag}` : packageName;
  try {
    const args = [...installCommand, finalSpecifier];
    await runBunCommand(args, directory);
    const installedIdentifier = packageName.startsWith("github:") ? (() => {
      const spec = packageName.replace(/^github:/, "");
      const [owner, repoWithRef] = spec.split("/");
      const repo = repoWithRef.split("#")[0];
      return `@${owner}/${repo}`;
    })() : packageName;
    return { success: true, installedIdentifier };
  } catch (error) {
    if (error.code === "ENOENT" || error.message?.includes("bun: command not found")) {
      logger16.warn(
        `Installation failed - bun command not found. ${displayBunInstallationTipCompact()}`
      );
    } else {
      logger16.warn(`Installation failed for ${finalSpecifier}: ${error.message}`);
    }
    return { success: false, installedIdentifier: null };
  }
}
function buildGitHubSpecifier(githubSpec, versionOrTag) {
  if (!versionOrTag) {
    return githubSpec;
  }
  const baseSpec = githubSpec.split("#")[0];
  return `${baseSpec}#${versionOrTag}`;
}
async function executeInstallationWithFallback(packageName, versionOrTag = "", directory = process.cwd(), githubFallback) {
  const result = await executeInstallation(packageName, versionOrTag, directory);
  if (result.success || !githubFallback) {
    return result;
  }
  logger16.debug(`npm installation failed, attempting GitHub fallback: ${githubFallback}`);
  await removeFromBunLock(packageName, directory);
  const githubSpecifier = `github:${githubFallback}${versionOrTag ? `#${versionOrTag}` : ""}`;
  return await executeInstallation(githubSpecifier, "", directory);
}

// src/utils/plugin-discovery.ts
import { logger as logger17 } from "@elizaos/core";
async function fetchPluginRegistry() {
  try {
    const resp = await fetch(
      "https://raw.githubusercontent.com/elizaos-plugins/registry/refs/heads/main/generated-registry.json"
    );
    if (!resp.ok) {
      logger17.error(`Failed to fetch plugin registry: ${resp.statusText}`);
      throw new Error(`Failed to fetch registry: ${resp.statusText}`);
    }
    const raw = await resp.json();
    return raw;
  } catch {
    return null;
  }
}

// src/utils/install-plugin.ts
function getCliDirectory() {
  try {
    const cliPath = process.argv[1];
    if (cliPath.includes("node_modules/@elizaos/cli")) {
      const cliDir = path16.dirname(
        cliPath.split("node_modules/@elizaos/cli")[0] + "node_modules/@elizaos/cli"
      );
      if (existsSync13(path16.join(cliDir, "package.json"))) {
        return cliDir;
      }
    }
    return null;
  } catch (error) {
    logger18.error("Failed to determine CLI directory:", error);
    return null;
  }
}
async function verifyPluginImport(repository, context) {
  const loadedModule = await loadPluginModule(repository);
  if (loadedModule) {
    logger18.debug(`Successfully verified plugin ${repository} ${context} after installation.`);
    return true;
  } else {
    logger18.warn(`Plugin ${repository} installed ${context} but could not be loaded/verified.`);
    return false;
  }
}
async function attemptInstallation(packageName, versionString, directory, context, skipVerification = false) {
  logger18.debug(`Attempting to install plugin ${context}...`);
  try {
    const installResult = await executeInstallation(packageName, versionString, directory);
    if (!installResult.success || !installResult.installedIdentifier) {
      logger18.warn(`Installation failed for plugin ${context}`);
      return false;
    }
    if (packageName.startsWith("github:")) {
      return true;
    }
    if (skipVerification || process.env.ELIZA_SKIP_PLUGIN_VERIFY) {
      logger18.info(
        `Installation successful for ${installResult.installedIdentifier}, skipping verification`
      );
      return true;
    }
    logger18.debug(
      `Installation successful for ${installResult.installedIdentifier}, verifying import...`
    );
    return await verifyPluginImport(installResult.installedIdentifier, context);
  } catch (installError) {
    logger18.warn(
      `Error during installation attempt ${context}: ${installError instanceof Error ? installError.message : String(installError)}`
    );
    return false;
  }
}
async function installPlugin(packageName, cwd, versionSpecifier, skipVerification = false) {
  logger18.debug(`Installing plugin: ${packageName}`);
  const context = detectPluginContext(packageName);
  if (context.isLocalDevelopment) {
    logger18.warn(`Prevented self-installation of plugin ${packageName}`);
    logger18.info(
      `You're developing this plugin locally. Use 'bun run build' to build it instead of installing.`
    );
    return false;
  }
  const cliDir = getCliDirectory();
  if (packageName.startsWith("github:")) {
    return await attemptInstallation(packageName, "", cwd, "", skipVerification);
  }
  const httpsGitHubUrlRegex = /^https?:\/\/github\.com\/([a-zA-Z0-9_-]+)\/([a-zA-Z0-9_.-]+?)(?:\.git)?(?:#([a-zA-Z0-9_.-]+))?\/?$/;
  const httpsMatch = packageName.match(httpsGitHubUrlRegex);
  if (httpsMatch) {
    const [, owner, repo, ref] = httpsMatch;
    const spec = `github:${owner}/${repo}${ref ? `#${ref}` : ""}`;
    return await attemptInstallation(spec, "", cwd, "", skipVerification);
  }
  const cache = await fetchPluginRegistry();
  const possible = normalizePluginName(packageName);
  let key = null;
  for (const name of possible) {
    if (cache?.registry[name]) {
      key = name;
      break;
    }
  }
  if (!key && cache && cache.registry) {
    let base = packageName;
    if (base.includes("/")) {
      const parts = base.split("/");
      base = parts[parts.length - 1];
    }
    base = base.replace(/^@/, "").replace(/^(plugin|client)-/, "");
    const lower = base.toLowerCase();
    const matches = Object.keys(cache.registry).filter(
      (cand) => cand.toLowerCase().includes(lower) && !cand.includes("client-")
    );
    if (matches.length > 0) {
      const pluginMatch = matches.find((c) => c.includes("plugin-"));
      key = pluginMatch || matches[0];
    }
  }
  if (!key) {
    logger18.warn(
      `Plugin ${packageName} not found in registry cache, attempting direct installation`
    );
    return await attemptInstallation(
      packageName,
      versionSpecifier || "",
      cwd,
      "",
      skipVerification
    );
  }
  const info = cache.registry[key];
  const githubFallback = info.git?.repo;
  const githubVersion = info.git?.v1?.branch || info.git?.v1?.version || "";
  if (info.npm?.repo) {
    const ver = versionSpecifier || info.npm.v1 || "";
    const result = await executeInstallationWithFallback(info.npm.repo, ver, cwd, githubFallback);
    if (result.success) {
      if (!info.npm.repo.startsWith("github:") && !skipVerification && !process.env.ELIZA_SKIP_PLUGIN_VERIFY) {
        const importSuccess = await verifyPluginImport(
          result.installedIdentifier || info.npm.repo,
          "from npm with potential GitHub fallback"
        );
        return importSuccess;
      }
      return true;
    }
  } else if (info.npm?.v1) {
    const result = await executeInstallationWithFallback(key, info.npm.v1, cwd, githubFallback);
    if (result.success) {
      if (!skipVerification && !process.env.ELIZA_SKIP_PLUGIN_VERIFY) {
        const importSuccess = await verifyPluginImport(
          result.installedIdentifier || key,
          "from npm registry with potential GitHub fallback"
        );
        return importSuccess;
      }
      return true;
    }
  }
  if (info.git?.repo && cliDir) {
    const spec = `github:${info.git.repo}${githubVersion ? `#${githubVersion}` : ""}`;
    return await attemptInstallation(spec, "", cliDir, "in CLI directory", skipVerification);
  }
  logger18.error(`Failed to install plugin ${packageName}`);
  return false;
}

// src/utils/port-handling.ts
import net from "net";
function isPortFree(port) {
  return new Promise((resolve2) => {
    const server = net.createServer();
    server.once("error", () => resolve2(false));
    server.once("listening", () => {
      server.close();
      resolve2(true);
    });
    server.listen(port);
  });
}
async function findNextAvailablePort(startPort) {
  let port = startPort;
  while (!await isPortFree(port)) {
    port++;
  }
  return port;
}

// src/utils/publisher.ts
import { execa as execa7 } from "execa";
import { logger as logger19 } from "@elizaos/core";
async function testPublishToNpm(cwd) {
  try {
    await execa7("npm", ["whoami"]);
    logger19.info("[\u2713] Logged in to npm");
    logger19.info("Testing build...");
    await execa7("npm", ["run", "build", "--dry-run"], { cwd });
    logger19.info("[\u2713] Build test successful");
    await execa7("npm", ["access", "ls-packages"], { cwd });
    logger19.info("[\u2713] Have publish permissions");
    return true;
  } catch (error) {
    logger19.error("Test failed:", error);
    if (error instanceof Error) {
      logger19.error(`Error message: ${error.message}`);
      logger19.error(`Error stack: ${error.stack}`);
    }
    return false;
  }
}
async function testPublishToGitHub(packageJson, username) {
  try {
    const credentials = await getGitHubCredentials();
    if (!credentials) {
      logger19.error("Failed to get GitHub credentials");
      return false;
    }
    const token = credentials.token;
    logger19.info("[\u2713] GitHub credentials found");
    const response = await fetch("https://api.github.com/user", {
      headers: { Authorization: `token ${token}` }
    });
    if (!response.ok) {
      logger19.error("Invalid GitHub token or insufficient permissions");
      return false;
    }
    logger19.info("[\u2713] GitHub token is valid");
    if (packageJson.packageType === "project") {
      logger19.info("[\u2713] Project validation complete - GitHub token is valid");
      return true;
    }
    const settings = await getRegistrySettings();
    const [registryOwner, registryRepo] = settings.defaultRegistry.split("/");
    logger19.info(`Testing with registry: ${registryOwner}/${registryRepo}`);
    const hasFork = await forkExists(token, registryRepo, username);
    logger19.info(hasFork ? "[\u2713] Fork exists" : "[\u2713] Can create fork");
    if (!hasFork) {
      logger19.info("Creating fork...");
      const forkCreated = await forkRepository(token, registryOwner, registryRepo);
      if (!forkCreated) {
        logger19.error("Failed to create fork");
        return false;
      }
      logger19.info("[\u2713] Fork created");
      await new Promise((resolve2) => setTimeout(resolve2, 3e3));
    }
    const branchName = `test-${packageJson.name.replace(/^@[^/]+\//, "")}-${packageJson.version}`;
    const hasBranch = await branchExists(token, username, registryRepo, branchName);
    logger19.info(hasBranch ? "[\u2713] Test branch exists" : "[\u2713] Can create branch");
    if (!hasBranch) {
      logger19.info("Creating branch...");
      const branchCreated = await createBranch(token, username, registryRepo, branchName, "main");
      if (!branchCreated) {
        logger19.error("Failed to create branch");
        return false;
      }
      logger19.info("[\u2713] Branch created");
    }
    const simpleName = packageJson.name.replace(/^@[^/]+\//, "").replace(/[^a-zA-Z0-9-]/g, "-");
    const testPath = `test-files/${simpleName}-test.json`;
    logger19.info(`Attempting to create test file: ${testPath} in branch: ${branchName}`);
    const dirCreated = await ensureDirectory(
      token,
      `${username}/${registryRepo}`,
      "test-files",
      branchName
    );
    if (!dirCreated) {
      logger19.warn("Failed to create test directory, but continuing with file creation");
    }
    const canUpdate = await updateFile(
      token,
      username,
      registryRepo,
      testPath,
      JSON.stringify({ test: true, timestamp: (/* @__PURE__ */ new Date()).toISOString() }),
      "Test file update",
      branchName
      // Use the test branch instead of main
    );
    if (!canUpdate) {
      logger19.error("Cannot update files in repository");
      return false;
    }
    logger19.info("[\u2713] Can create and update files");
    return true;
  } catch (error) {
    logger19.error("Test failed:", error);
    return false;
  }
}
async function publishToNpm(cwd) {
  try {
    await execa7("npm", ["whoami"]);
    logger19.info("Building package...");
    await execa7("npm", ["run", "build"], { cwd, stdio: "inherit" });
    logger19.info("Publishing to npm...");
    await execa7("npm", ["publish"], { cwd, stdio: "inherit" });
    return true;
  } catch (error) {
    logger19.error("Failed to publish to npm:", error);
    return false;
  }
}
async function publishToGitHub(cwd, packageJson, username, skipRegistry = false, isTest = false) {
  const credentials = await getGitHubCredentials();
  if (!credentials) {
    logger19.error("Failed to get GitHub credentials");
    return false;
  }
  const token = credentials.token;
  if (!packageJson.packageType) {
    logger19.error(
      'Package type is required. Set "packageType" to either "plugin" or "project" in package.json'
    );
    return false;
  }
  if (packageJson.packageType !== "plugin" && packageJson.packageType !== "project") {
    logger19.error(
      `Invalid package type: ${packageJson.packageType}. Must be either "plugin" or "project"`
    );
    return false;
  }
  if (isTest) {
    logger19.info("Running in test mode - no actual changes will be made");
  }
  if (skipRegistry) {
    logger19.info("Registry updates will be skipped as requested with --skip-registry flag");
  }
  if (!isTest) {
    const repoName = packageJson.name.replace(/^@[^/]+\//, "");
    const description = packageJson.description || `ElizaOS ${packageJson.packageType}`;
    let topic;
    if (packageJson.packageType === "plugin") {
      topic = "elizaos-plugins";
    } else if (packageJson.packageType === "project") {
      topic = "elizaos-projects";
    } else {
      topic = "elizaos-plugins";
    }
    logger19.info(`Checking/creating GitHub repository: ${username}/${repoName}`);
    const repoResult = await createGitHubRepository(token, repoName, description, false, [topic]);
    if (!repoResult.success) {
      logger19.error(`Failed to create GitHub repository: ${repoResult.message}`);
      return false;
    }
    logger19.info(`Using repository: ${repoResult.repoUrl}`);
    const repoUrl = `https://${token}@github.com/${username}/${repoName}.git`;
    logger19.info("Pushing code to GitHub...");
    const pushSuccess = await pushToGitHub(cwd, repoUrl);
    if (!pushSuccess) {
      logger19.error("Failed to push code to GitHub repository.");
      return false;
    }
    logger19.success("Successfully pushed code to GitHub repository");
    if (packageJson.packageType === "project" || skipRegistry) {
      const reason = packageJson.packageType === "project" ? "Projects do not need registry updates" : "Registry updates skipped as requested with --skip-registry flag";
      logger19.info(`${packageJson.name} published to GitHub successfully. ${reason}`);
      return {
        success: true,
        prUrl: repoResult.repoUrl
      };
    }
  }
  if (packageJson.packageType === "project" || skipRegistry) {
    if (isTest) {
      logger19.info("Test successful - project would be published to GitHub only");
    }
    return true;
  }
  const settings = await getRegistrySettings();
  const [registryOwner, registryRepo] = settings.defaultRegistry.split("/");
  const hasFork = await forkExists(token, registryRepo, username);
  let forkFullName;
  if (!hasFork && !isTest) {
    logger19.info(`Creating fork of ${settings.defaultRegistry}...`);
    const fork = await forkRepository(token, registryOwner, registryRepo);
    if (!fork) {
      logger19.error("Failed to fork registry repository.");
      return false;
    }
    forkFullName = fork;
    await new Promise((resolve2) => setTimeout(resolve2, 2e3));
  } else {
    forkFullName = `${username}/${registryRepo}`;
    logger19.info(`Using existing fork: ${forkFullName}`);
  }
  const entityType = packageJson.packageType;
  const packageNameWithoutScope = packageJson.name.replace(/^@[^/]+\//, "");
  let branchName;
  if (entityType === "plugin" && packageNameWithoutScope.startsWith("plugin-")) {
    branchName = `${packageNameWithoutScope}-${packageJson.version}`;
    logger19.info(`Using package name directly to avoid duplicate plugin prefix: ${branchName}`);
  } else {
    branchName = `${entityType}-${packageNameWithoutScope}-${packageJson.version}`;
  }
  const hasBranch = await branchExists(token, username, registryRepo, branchName);
  if (!hasBranch && !isTest) {
    logger19.info(`Creating branch ${branchName}...`);
    const created = await createBranch(token, username, registryRepo, branchName);
    if (!created) {
      logger19.error("Failed to create branch.");
      return false;
    }
  }
  const packageName = packageJson.name.replace(/^@[^/]+\//, "");
  const registryPackageName = packageJson.name;
  if (!isTest) {
    try {
      const indexContent = await getFileContent(token, username, registryRepo, "index.json");
      if (indexContent) {
        const githubRepo = `github:${username}/${packageName}`;
        const index = JSON.parse(indexContent);
        if (index[registryPackageName]) {
          logger19.warn(`Package ${registryPackageName} already exists in registry`);
          return false;
        }
        logger19.info(`Adding registry entry: ${registryPackageName} -> ${githubRepo}`);
        const lines = indexContent.split("\n");
        const newEntry = `    "${registryPackageName}": "${githubRepo}",`;
        let insertIndex = -1;
        for (let i = 0; i < lines.length; i++) {
          const line = lines[i].trim();
          if (!line || line === "{") continue;
          if (line === "}") {
            insertIndex = i;
            break;
          }
          const match = line.match(/^\s*"(@[^"]+)"/);
          if (match) {
            const existingPackage = match[1];
            if (registryPackageName < existingPackage) {
              insertIndex = i;
              break;
            }
          }
        }
        if (insertIndex === -1) {
          for (let i = lines.length - 1; i >= 0; i--) {
            if (lines[i].trim() === "}") {
              insertIndex = i;
              break;
            }
          }
        }
        if (insertIndex === -1) {
          logger19.error("Could not find insertion point in index.json");
          return false;
        }
        lines.splice(insertIndex, 0, newEntry);
        const updatedContent = lines.join("\n");
        const indexUpdated = await updateFile(
          token,
          username,
          registryRepo,
          "index.json",
          updatedContent,
          `Add ${registryPackageName} to registry`,
          branchName
        );
        if (!indexUpdated) {
          logger19.error("Failed to update registry index.");
          return false;
        }
      } else {
        logger19.error("Could not fetch index.json from registry");
        return false;
      }
    } catch (error) {
      logger19.error(
        `Failed to update index.json: ${error instanceof Error ? error.message : String(error)}`
      );
      return false;
    }
    const prUrl = await createPullRequest(
      token,
      registryOwner,
      registryRepo,
      `Add ${registryPackageName} to registry`,
      `This PR adds ${registryPackageName} to the registry.

- Package name: ${registryPackageName}
- GitHub repository: github:${username}/${packageName}
- Version: ${packageJson.version}
- Description: ${packageJson.description || "No description provided"}

Submitted by: @${username}`,
      `${username}:${branchName}`,
      "main"
    );
    if (!prUrl) {
      logger19.error("Failed to create pull request.");
      return false;
    }
    logger19.success(`Pull request created: ${prUrl}`);
    return {
      success: true,
      prUrl
    };
  } else {
    logger19.info("Test successful - all checks passed");
    logger19.info("Would create:");
    logger19.info(`- Branch: ${branchName}`);
    logger19.info(`- Registry entry: ${registryPackageName} -> github:${username}/${packageName}`);
    logger19.info(`- Pull request: Add ${registryPackageName} to registry`);
  }
  return true;
}

// src/utils/resolve-import.ts
import { createMatchPath } from "tsconfig-paths";
async function resolveImport(importPath, config) {
  return createMatchPath(config.absoluteBaseUrl, config.paths)(importPath, void 0, () => true, [
    ".ts"
  ]);
}

// src/utils/test-runner.ts
import {
  logger as logger20
} from "@elizaos/core";
import * as fs9 from "fs";
import * as path17 from "path";
import { pathToFileURL } from "url";
var safeLogger = {
  debug: logger20?.debug || console.log,
  info: logger20?.info || console.log,
  warn: logger20?.warn || console.warn,
  error: logger20?.error || console.error,
  success: logger20?.success || console.log
};
var TestRunner = class {
  runtime;
  projectAgent;
  stats;
  isDirectPluginTest;
  pluginUnderTest;
  constructor(runtime, projectAgent) {
    this.runtime = runtime;
    this.projectAgent = projectAgent;
    this.stats = {
      total: 0,
      passed: 0,
      failed: 0,
      skipped: 0,
      hasTests: false
    };
    const testingPlugin = process.env.ELIZA_TESTING_PLUGIN === "true";
    if (testingPlugin && projectAgent?.plugins) {
      const corePlugins = ["@elizaos/plugin-sql"];
      const nonCorePlugins = projectAgent.plugins.filter(
        (plugin) => !corePlugins.includes(plugin.name)
      );
      if (nonCorePlugins.length > 0) {
        this.pluginUnderTest = nonCorePlugins[0];
        this.isDirectPluginTest = true;
        safeLogger.debug(
          `Direct plugin test detected - will only run tests for plugin: ${this.pluginUnderTest.name}`
        );
      } else {
        this.isDirectPluginTest = false;
      }
    } else if (projectAgent?.plugins?.length === 1 && (projectAgent.character.name.includes(`Test Agent for ${projectAgent.plugins[0].name}`) || projectAgent.character.name.toLowerCase().includes("test") && projectAgent.character.name.toLowerCase().includes(projectAgent.plugins[0].name.toLowerCase()))) {
      this.pluginUnderTest = projectAgent.plugins[0];
      this.isDirectPluginTest = true;
      safeLogger.debug(
        `Direct plugin test detected - will only run tests for plugin: ${this.pluginUnderTest.name}`
      );
    } else {
      this.isDirectPluginTest = false;
    }
  }
  /**
   * Helper method to check if a test suite name matches the filter
   * @param name The name of the test suite
   * @param filter Optional filter string
   * @returns True if the name matches the filter or if no filter is specified
   */
  matchesFilter(name, filter) {
    if (!filter) return true;
    let processedFilter = filter;
    if (processedFilter.endsWith(".test.ts") || processedFilter.endsWith(".test.js")) {
      processedFilter = processedFilter.slice(0, -8);
    } else if (processedFilter.endsWith(".test")) {
      processedFilter = processedFilter.slice(0, -5);
    }
    return name.toLowerCase().includes(processedFilter.toLowerCase());
  }
  /**
   * Runs a test suite
   * @param suite The test suite to run
   */
  async runTestSuite(suite) {
    safeLogger.info(`
Running test suite: ${suite.name}`);
    if (suite.tests.length > 0) {
      this.stats.hasTests = true;
    }
    for (const test of suite.tests) {
      this.stats.total++;
      try {
        safeLogger.info(`  Running test: ${test.name}`);
        await test.fn(this.runtime);
        this.stats.passed++;
        safeLogger.success(`  [\u2713] ${test.name}`);
      } catch (error) {
        this.stats.failed++;
        safeLogger.error(`  [X] ${test.name}`);
        safeLogger.error(`    ${error instanceof Error ? error.message : String(error)}`);
      }
    }
  }
  /**
   * Runs project agent tests
   */
  async runProjectTests(options) {
    if (!this.projectAgent?.tests || options.skipProjectTests || this.isDirectPluginTest) {
      if (this.isDirectPluginTest) {
        safeLogger.info("Skipping project tests when directly testing a plugin");
      }
      return;
    }
    safeLogger.info("\nRunning project tests...");
    const testSuites = Array.isArray(this.projectAgent.tests) ? this.projectAgent.tests : [this.projectAgent.tests];
    for (const suite of testSuites) {
      if (!suite) {
        continue;
      }
      if (!this.matchesFilter(suite.name, options.filter)) {
        safeLogger.info(
          `Skipping test suite "${suite.name}" (doesn't match filter "${options.filter}")`
        );
        this.stats.skipped++;
        continue;
      }
      await this.runTestSuite(suite);
    }
  }
  /**
   * Runs plugin tests (only when in a plugin directory)
   */
  async runPluginTests(options) {
    if (options.skipPlugins) {
      return;
    }
    if (this.isDirectPluginTest) {
      safeLogger.info("\nRunning plugin tests...");
      const plugin = this.pluginUnderTest;
      if (!plugin || !plugin.tests) {
        safeLogger.info(`No tests found for this plugin (${plugin?.name || "unknown plugin"})`);
        safeLogger.info(
          "To add tests to your plugin, include a 'tests' property with an array of test suites."
        );
        safeLogger.info("Example:");
        safeLogger.info(`
export const myPlugin = {
  name: "my-plugin",
  description: "My awesome plugin",
  
  // ... other plugin properties ...
  
  tests: [
    {
      name: "Basic Tests",
      tests: [
        {
          name: "should do something",
          fn: async (runtime) => {
            // Test code here
          }
        }
      ]
    }
  ]
};
`);
        return;
      }
      safeLogger.info(`Found test suites for plugin: ${plugin.name}`);
      const testSuites = Array.isArray(plugin.tests) ? plugin.tests : [plugin.tests];
      for (const suite of testSuites) {
        if (!suite) {
          continue;
        }
        if (!this.matchesFilter(suite.name, options.filter)) {
          safeLogger.info(
            `Skipping test suite "${suite.name}" because it doesn't match filter "${options.filter}"`
          );
          this.stats.skipped++;
          continue;
        }
        await this.runTestSuite(suite);
      }
    } else {
      safeLogger.info("Plugin tests were requested but this is not a direct plugin test");
    }
  }
  /**
   * Runs tests from the e2e directory
   */
  async runE2eTests(options) {
    if (options.skipE2eTests) {
      safeLogger.info("Skipping e2e tests (--skip-e2e-tests flag)");
      return;
    }
    try {
      const e2eDir = path17.join(process.cwd(), "e2e");
      if (!fs9.existsSync(e2eDir)) {
        safeLogger.debug("No e2e directory found, skipping e2e tests");
        return;
      }
      safeLogger.info("\nRunning e2e tests...");
      const walk = (dir) => fs9.readdirSync(dir, { withFileTypes: true }).flatMap(
        (entry) => entry.isDirectory() ? walk(path17.join(dir, entry.name)) : entry.name.match(/\.test\.(t|j)sx?$/) ? [path17.join(dir, entry.name)] : []
      );
      const testFiles = walk(e2eDir);
      if (testFiles.length === 0) {
        safeLogger.info("No e2e test files found");
        return;
      }
      safeLogger.info(`Found ${testFiles.length} e2e test files`);
      const distE2eDir = path17.join(process.cwd(), "dist", "e2e");
      const hasDistE2e = fs9.existsSync(distE2eDir);
      for (const testFile of testFiles) {
        try {
          const fileName = path17.basename(testFile);
          const fileNameWithoutExt = path17.basename(testFile, ".test.ts");
          safeLogger.info(`Loading test file: ${fileName}`);
          let moduleImportPath = testFile;
          if (hasDistE2e) {
            const distFile = path17.join(distE2eDir, `${fileNameWithoutExt}.test.js`);
            if (fs9.existsSync(distFile)) {
              moduleImportPath = distFile;
              safeLogger.debug(`Using compiled version from ${distFile}`);
            } else {
              safeLogger.warn(
                `No compiled version found for ${fileName}, attempting to import TypeScript directly (may fail)`
              );
            }
          } else {
            safeLogger.warn(
              `No dist/e2e directory found. E2E tests should be compiled first. Import may fail.`
            );
          }
          let testModule;
          try {
            testModule = await import(pathToFileURL(moduleImportPath).href);
          } catch (importError) {
            safeLogger.error(`Failed to import test file ${fileName}:`, importError);
            safeLogger.info(
              `Make sure your e2e tests are properly compiled with 'npm run build' or 'bun run build'`
            );
            this.stats.failed++;
            continue;
          }
          const testSuite = testModule.default;
          if (!testSuite || !testSuite.tests) {
            safeLogger.warn(`No valid test suite found in ${fileName}`);
            continue;
          }
          if (options.filter) {
            const processedFilter = options.filter;
            const matchesFileName = fileNameWithoutExt.toLowerCase() === processedFilter.toLowerCase() || fileNameWithoutExt.toLowerCase().includes(processedFilter.toLowerCase());
            const matchesSuiteName = testSuite.name ? testSuite.name.toLowerCase().includes(processedFilter.toLowerCase()) : false;
            if (!matchesFileName && !matchesSuiteName) {
              safeLogger.info(
                `Skipping test suite "${testSuite.name || "unnamed"}" in ${fileName} (doesn't match filter "${options.filter}")`
              );
              this.stats.skipped++;
              continue;
            }
          }
          await this.runTestSuite(testSuite);
        } catch (error) {
          safeLogger.error(`Error running tests from ${testFile}:`, error);
          this.stats.failed++;
        }
      }
    } catch (error) {
      safeLogger.error(`Error running e2e tests:`, error);
    }
  }
  /**
   * Runs all tests in the project
   * @param options Test options
   */
  async runTests(options = {}) {
    await this.runProjectTests(options);
    await this.runPluginTests(options);
    await this.runE2eTests(options);
    if (!this.stats.hasTests) {
      safeLogger.info("\nNo test files found, exiting with code 0");
    } else {
      safeLogger.info(
        `
Test Summary: ${this.stats.passed} passed, ${this.stats.failed} failed, ${this.stats.skipped} skipped`
      );
    }
    return this.stats;
  }
};

// src/utils/registry/index.ts
import { logger as logger21 } from "@elizaos/core";
import dotenv3 from "dotenv";
import { execa as execa8 } from "execa";
import { HttpsProxyAgent } from "https-proxy-agent";
import { existsSync as existsSync15, promises as fs10 } from "fs";
import path18 from "path";

// src/utils/registry/constants.ts
var REGISTRY_ORG = "elizaos-plugins";
var REGISTRY_REPO_NAME = "registry";
var REGISTRY_REPO = `${REGISTRY_ORG}/${REGISTRY_REPO_NAME}`;
var REGISTRY_URL = `https://raw.githubusercontent.com/${REGISTRY_REPO}/refs/heads/main/index.json`;
var REGISTRY_GITHUB_URL = `https://github.com/${REGISTRY_REPO}`;
var RAW_REGISTRY_URL = REGISTRY_URL;

// src/utils/registry/index.ts
var ELIZA_DIR = path18.join(process.cwd(), ".eliza");
var REGISTRY_SETTINGS_FILE = path18.join(ELIZA_DIR, "registrysettings.json");
var ENV_FILE = resolveEnvFile() || path18.join(ELIZA_DIR, ".env");
var REGISTRY_CACHE_FILE = path18.join(ELIZA_DIR, "registry-cache.json");
var REQUIRED_ENV_VARS = ["GITHUB_TOKEN"];
var REQUIRED_SETTINGS = ["defaultRegistry"];
async function ensureElizaDir2() {
  try {
    await fs10.mkdir(ELIZA_DIR, { recursive: true });
  } catch (error) {
  }
}
async function getRegistrySettings() {
  await ensureElizaDir2();
  try {
    const content = await fs10.readFile(REGISTRY_SETTINGS_FILE, "utf-8");
    return JSON.parse(content);
  } catch (error) {
    return {
      defaultRegistry: REGISTRY_REPO
    };
  }
}
async function saveRegistrySettings(settings) {
  await ensureElizaDir2();
  await fs10.writeFile(REGISTRY_SETTINGS_FILE, JSON.stringify(settings, null, 2));
}
async function getEnvVar(key) {
  try {
    const envContent = await fs10.readFile(ENV_FILE, "utf-8");
    const env = dotenv3.parse(envContent);
    return env[key];
  } catch (error) {
    return void 0;
  }
}
async function setEnvVar(key, value) {
  await ensureElizaDir2();
  let envContent = "";
  try {
    envContent = await fs10.readFile(ENV_FILE, "utf-8");
  } catch (error) {
  }
  const env = dotenv3.parse(envContent);
  env[key] = value;
  const newContent = Object.entries(env).map(([k, v]) => `${k}=${v}`).join("\n");
  await fs10.writeFile(ENV_FILE, newContent);
}
async function getGitHubToken() {
  try {
    const envPath = resolveEnvFile();
    if (envPath && existsSync15(envPath)) {
      const envContent = await fs10.readFile(envPath, "utf-8");
      const env = dotenv3.parse(envContent);
      return env.GITHUB_TOKEN;
    }
    const globalEnvPath = path18.join(ELIZA_DIR, ".env");
    if (existsSync15(globalEnvPath) && globalEnvPath !== envPath) {
      const envContent = await fs10.readFile(globalEnvPath, "utf-8");
      const env = dotenv3.parse(envContent);
      return env.GITHUB_TOKEN;
    }
  } catch (error) {
    logger21.debug(
      `Error reading GitHub token: ${error instanceof Error ? error.message : String(error)}`
    );
  }
  return void 0;
}
async function setGitHubToken(token) {
  await ensureElizaDir2();
  try {
    let envContent = "";
    try {
      if (existsSync15(ENV_FILE)) {
        envContent = await fs10.readFile(ENV_FILE, "utf-8");
      }
    } catch (error) {
      envContent = "# Eliza environment variables\n\n";
    }
    const env = dotenv3.parse(envContent);
    env.GITHUB_TOKEN = token;
    let newContent = "";
    for (const [key, value] of Object.entries(env)) {
      newContent += `${key}=${value}
`;
    }
    await fs10.writeFile(ENV_FILE, newContent);
    process.env.GITHUB_TOKEN = token;
    logger21.debug("GitHub token saved successfully");
  } catch (error) {
    logger21.error(
      `Failed to save GitHub token: ${error instanceof Error ? error.message : String(error)}`
    );
  }
}
function normalizePackageName(packageName) {
  if (packageName.startsWith(`@${REGISTRY_ORG}/`)) {
    return packageName.replace(`@${REGISTRY_ORG}/`, "");
  } else if (packageName.startsWith("@elizaos/")) {
    return packageName.replace(/^@elizaos\//, "");
  }
  return packageName;
}
var DEFAULT_REGISTRY = {
  "@elizaos/plugin-anthropic": "github:elizaos-plugins/plugin-anthropic",
  "@elizaos/plugin-bootstrap": "github:elizaos-plugins/plugin-bootstrap",
  "@elizaos/plugin-browser": "github:elizaos-plugins/plugin-browser",
  "@elizaos/plugin-discord": "github:elizaos-plugins/plugin-discord",
  "@elizaos/plugin-elevenlabs": "github:elizaos-plugins/plugin-elevenlabs",
  "@elizaos/plugin-evm": "github:elizaos-plugins/plugin-evm",
  "@elizaos/plugin-farcaster": "github:elizaos-plugins/plugin-farcaster",
  "@elizaos/plugin-groq": "github:elizaos-plugins/plugin-groq",
  "@elizaos/plugin-local-ai": "github:elizaos-plugins/plugin-local-ai",
  "@elizaos/plugin-mcp": "github:elizaos-plugins/plugin-mcp",
  "@elizaos/plugin-messari-ai-toolkit": "github:messari/plugin-messari-ai-toolkit",
  "@elizaos/plugin-morpheus": "github:bowtiedbluefin/plugin-morpheus",
  "@elizaos/plugin-node": "github:elizaos-plugins/plugin-node",
  "@elizaos/plugin-ollama": "github:elizaos-plugins/plugin-ollama",
  "@elizaos/plugin-openai": "github:elizaos-plugins/plugin-openai",
  "@elizaos/plugin-pdf": "github:elizaos-plugins/plugin-pdf",
  "@elizaos/plugin-redpill": "github:elizaos-plugins/plugin-redpill",
  "@elizaos/plugin-solana": "github:elizaos-plugins/plugin-solana",
  "@elizaos/plugin-sql": "github:elizaos-plugins/plugin-sql",
  "@elizaos/plugin-storage-s3": "github:elizaos-plugins/plugin-storage-s3",
  "@elizaos/plugin-tee": "github:elizaos-plugins/plugin-tee",
  "@elizaos/plugin-telegram": "github:elizaos-plugins/plugin-telegram",
  "@elizaos/plugin-twitter": "github:elizaos-plugins/plugin-twitter",
  "@elizaos/plugin-venice": "github:elizaos-plugins/plugin-venice",
  "@elizaos/plugin-video-understanding": "github:elizaos-plugins/plugin-video-understanding"
};
async function saveRegistryCache(registry) {
  try {
    await ensureElizaDir2();
    await fs10.writeFile(REGISTRY_CACHE_FILE, JSON.stringify(registry, null, 2));
    logger21.debug("Registry cache saved successfully");
  } catch (error) {
    logger21.debug(
      `Failed to save registry cache: ${error instanceof Error ? error.message : String(error)}`
    );
  }
}
async function getLocalRegistryIndex() {
  try {
    logger21.debug("Fetching registry from public GitHub URL");
    const response = await fetch(RAW_REGISTRY_URL);
    if (response.ok) {
      const rawData = await response.json();
      const result = {};
      if (typeof rawData === "object" && rawData !== null) {
        for (const [key, value] of Object.entries(rawData)) {
          if (typeof value === "string") {
            result[key] = value;
          }
        }
        await saveRegistryCache(result);
        logger21.debug("Successfully fetched registry from public GitHub URL");
        return result;
      }
    }
  } catch (error) {
    logger21.debug(
      `Failed to fetch registry from public URL: ${error instanceof Error ? error.message : String(error)}`
    );
  }
  try {
    if (existsSync15(REGISTRY_CACHE_FILE)) {
      const cacheContent = await fs10.readFile(REGISTRY_CACHE_FILE, "utf-8");
      const cachedRegistry = JSON.parse(cacheContent);
      logger21.debug("Using cached registry index");
      return cachedRegistry;
    }
  } catch (error) {
    logger21.debug(
      `Failed to read registry cache: ${error instanceof Error ? error.message : String(error)}`
    );
  }
  const directoryInfo = detectDirectoryType(process.cwd());
  if (directoryInfo.monorepoRoot) {
    try {
      const localPackages = await getLocalPackages();
      const localRegistry = {};
      for (const pkgName of localPackages) {
        if (pkgName.includes("plugin-")) {
          const repoName = normalizePackageName(pkgName);
          localRegistry[pkgName] = `${REGISTRY_ORG}/${repoName}`;
        }
      }
      return { ...DEFAULT_REGISTRY, ...localRegistry };
    } catch (error) {
      logger21.debug(
        `Failed to discover local plugins: ${error instanceof Error ? error.message : String(error)}`
      );
    }
  }
  return DEFAULT_REGISTRY;
}
async function getRegistryIndex() {
  const settings = await getRegistrySettings();
  const credentials = await getGitHubCredentials();
  if (!credentials) {
    logger21.error("GitHub credentials not found. Please run login first.");
    process.exit(1);
  }
  const [owner, repo] = settings.defaultRegistry.split("/");
  const url = `https://api.github.com/repos/${owner}/${repo}/contents/index.json`;
  const response = await fetch(url, {
    headers: {
      Authorization: `token ${credentials.token}`,
      Accept: "application/vnd.github.v3.raw"
    }
  });
  if (!response.ok) {
    throw new Error(`Failed to fetch registry index: ${response.statusText}`);
  }
  const data = await response.json();
  if (typeof data !== "object" || data === null) {
    throw new Error("Invalid registry index format");
  }
  const result = {};
  for (const [key, value] of Object.entries(data)) {
    if (typeof value === "string") {
      result[key] = value;
    }
  }
  return result;
}
function normalizePluginName(pluginName) {
  let baseName = pluginName;
  if (pluginName.includes("/")) {
    const parts = pluginName.split("/");
    baseName = parts[parts.length - 1];
  } else if (pluginName.startsWith("@")) {
    const parts = pluginName.split("/");
    if (parts.length > 1) {
      baseName = parts[1];
    }
  }
  baseName = baseName.replace(/^plugin-/, "");
  return [
    pluginName,
    // Original input
    baseName,
    // Just the base name
    `plugin-${baseName}`,
    // With plugin- prefix
    `@elizaos/${baseName}`,
    // Scoped with elizaos
    `@elizaos/plugin-${baseName}`
    // Scoped with elizaos and plugin prefix
  ];
}
async function getPluginRepository(pluginName) {
  try {
    const possibleNames = normalizePluginName(pluginName);
    const registry = await getLocalRegistryIndex();
    for (const name of possibleNames) {
      if (registry[name]) {
        logger21.debug(`Found plugin in registry as: ${name}`);
        return registry[name];
      }
    }
    if (pluginName.startsWith("@")) {
      return pluginName;
    }
    if (!pluginName.includes(":") && !pluginName.startsWith("@")) {
      const baseName = pluginName.replace(/^plugin-/, "");
      return `@${REGISTRY_ORG}/plugin-${baseName}`;
    }
    return null;
  } catch (error) {
    logger21.debug(
      `Error getting plugin repository: ${error instanceof Error ? error.message : String(error)}`
    );
    return null;
  }
}
async function repoHasBranch(repoUrl, branchName) {
  try {
    const { stdout } = await execa8("git", ["ls-remote", "--heads", repoUrl, branchName]);
    return stdout.includes(branchName);
  } catch (error) {
    logger21.warn(
      `Failed to check for branch ${branchName} in ${repoUrl}: ${error instanceof Error ? error.message : String(error)}`
    );
    return false;
  }
}
async function getBestBranch(repoUrl) {
  if (await repoHasBranch(repoUrl, "v2")) {
    return "v2";
  }
  if (await repoHasBranch(repoUrl, "v2-develop")) {
    return "v2-develop";
  }
  return "main";
}
async function listPluginsByType(type) {
  const registry = await getRegistryIndex();
  return Object.keys(registry).filter((name) => !type || name.includes(type)).sort();
}
async function getPluginMetadata(pluginName) {
  const settings = await getRegistrySettings();
  const credentials = await getGitHubCredentials();
  if (!credentials) {
    logger21.error("GitHub credentials not found. Please run login first.");
    process.exit(1);
  }
  const [owner, repo] = settings.defaultRegistry.split("/");
  const normalizedName = normalizePackageName(pluginName);
  const url = `https://api.github.com/repos/${owner}/${repo}/contents/packages/${normalizedName}.json`;
  try {
    const response = await fetch(url, {
      headers: {
        Authorization: `token ${credentials.token}`,
        Accept: "application/vnd.github.v3.raw"
      }
    });
    if (!response.ok) {
      if (response.status === 404) {
        return null;
      }
      throw new Error(`Failed to fetch plugin metadata: ${response.statusText}`);
    }
    const data = await response.json();
    if (typeof data !== "object" || data === null) {
      throw new Error("Invalid plugin metadata format");
    }
    const metadata = data;
    if (!metadata.name || !metadata.description || !metadata.author || !metadata.repository || !metadata.versions || !metadata.latestVersion || !metadata.runtimeVersion || !metadata.maintainer) {
      throw new Error("Invalid plugin metadata: missing required fields");
    }
    return metadata;
  } catch (error) {
    logger21.error("Failed to fetch plugin metadata:", error);
    return null;
  }
}
async function getPluginVersion(pluginName, version) {
  if (version) {
    return version;
  }
  try {
    const packageDetails = await getPackageDetails(pluginName);
    if (packageDetails?.latestVersion) {
      return packageDetails.latestVersion;
    }
  } catch (error) {
    logger21.debug(
      `Error getting package details: ${error instanceof Error ? error.message : String(error)}`
    );
  }
  return "latest";
}
async function getPluginTags(pluginName) {
  const metadata = await getPluginMetadata(pluginName);
  return metadata?.tags || [];
}
async function getPluginCategories(pluginName) {
  const metadata = await getPluginMetadata(pluginName);
  return metadata?.categories || [];
}
async function getAvailableDatabases() {
  const registry = await getRegistryIndex();
  return Object.keys(registry).filter((name) => name.includes("database-")).sort();
}
async function getPackageDetails(packageName) {
  try {
    const normalizedName = normalizePackageName(packageName);
    const packageUrl = `${REGISTRY_URL.replace("index.json", "")}packages/${normalizedName}.json`;
    const requestOptions = {};
    if (process.env.https_proxy) {
      requestOptions.agent = new HttpsProxyAgent(process.env.https_proxy);
    }
    const response = await fetch(packageUrl, requestOptions);
    if (response.status !== 200) {
      return null;
    }
    const text5 = await response.text();
    try {
      return JSON.parse(text5);
    } catch {
      logger21.warn(`Invalid JSON response received from registry for package ${packageName}:`, text5);
      return null;
    }
  } catch (error) {
    logger21.warn(
      `Failed to fetch package details from registry: ${error instanceof Error ? error.message : String(error)}`
    );
    return null;
  }
}
async function getBestPluginVersion(packageName, runtimeVersion) {
  const packageDetails = await getPackageDetails(packageName);
  if (!packageDetails || !packageDetails.versions || packageDetails.versions.length === 0) {
    return null;
  }
  if (packageDetails.runtimeVersion === runtimeVersion) {
    return packageDetails.latestVersion;
  }
  const [runtimeMajor, runtimeMinor] = runtimeVersion.split(".").map(Number);
  const [packageMajor, packageMinor] = packageDetails.runtimeVersion.split(".").map(Number);
  if (runtimeMajor !== packageMajor) {
    logger21.warn(
      `Plugin ${packageName} was built for runtime v${packageDetails.runtimeVersion}, but you're using v${runtimeVersion}`
    );
    logger21.warn("This may cause compatibility issues.");
    return packageDetails.latestVersion;
  }
  if (runtimeMinor !== packageMinor) {
    logger21.warn(
      `Plugin ${packageName} was built for runtime v${packageDetails.runtimeVersion}, you're using v${runtimeVersion}`
    );
  }
  return packageDetails.latestVersion;
}
async function checkDataDir() {
  const status = {
    exists: false,
    env: {
      exists: false,
      missingKeys: [...REQUIRED_ENV_VARS],
      hasAllKeys: false
    },
    settings: {
      exists: false,
      missingKeys: [...REQUIRED_SETTINGS],
      hasAllKeys: false
    }
  };
  try {
    await fs10.access(ELIZA_DIR);
    status.exists = true;
  } catch {
    return status;
  }
  try {
    const envContent = await fs10.readFile(ENV_FILE, "utf-8");
    const env = dotenv3.parse(envContent);
    status.env.exists = true;
    status.env.missingKeys = REQUIRED_ENV_VARS.filter((key) => !env[key]);
    status.env.hasAllKeys = status.env.missingKeys.length === 0;
  } catch {
  }
  try {
    const settingsContent = await fs10.readFile(REGISTRY_SETTINGS_FILE, "utf-8");
    const settings = JSON.parse(settingsContent);
    status.settings.exists = true;
    status.settings.missingKeys = REQUIRED_SETTINGS.filter((key) => !(key in settings));
    status.settings.hasAllKeys = status.settings.missingKeys.length === 0;
  } catch {
  }
  return status;
}
async function initializeDataDir() {
  await ensureElizaDir2();
  try {
    await fs10.access(ENV_FILE);
  } catch {
    await fs10.writeFile(ENV_FILE, "");
  }
  try {
    await fs10.access(REGISTRY_SETTINGS_FILE);
  } catch {
    await saveRegistrySettings({
      defaultRegistry: REGISTRY_REPO
    });
  }
}
async function validateDataDir() {
  const status = await checkDataDir();
  if (!status.exists) {
    logger21.warn("ElizaOS data directory not found. Initializing...");
    await initializeDataDir();
    return false;
  }
  let isValid = true;
  const envPath = resolveEnvFile();
  if (envPath) {
    const envContent = await fs10.readFile(envPath, "utf-8");
    const parsedEnv = dotenv3.parse(envContent);
    if (!parsedEnv.GITHUB_TOKEN) {
      logger21.warn("GitHub token not found in environment");
      isValid = false;
    }
  } else {
    logger21.warn(".env file not found");
    isValid = false;
  }
  if (!status.env.hasAllKeys) {
    logger21.warn(`Missing environment variables: ${status.env.missingKeys.join(", ")}`);
    isValid = false;
  }
  if (!status.settings.exists) {
    logger21.warn("Registry settings file not found");
    isValid = false;
  } else if (!status.settings.hasAllKeys) {
    logger21.warn(`Missing settings: ${status.settings.missingKeys.join(", ")}`);
    isValid = false;
  }
  return isValid;
}

export {
  expandTildePath,
  resolveEnvFile,
  resolvePgliteDir,
  UserEnvironment,
  detectDirectoryType,
  isValidForUpdates,
  buildProject,
  isBunAvailable,
  isCliInstalledViaNpm,
  migrateCliToBun,
  NAV_BACK,
  NAV_NEXT,
  promptWithNav,
  promptForMultipleItems,
  confirmAction,
  getEnvFilePath,
  readEnvFile,
  writeEnvFile,
  promptForEnvVars,
  validateEnvVars,
  getMissingEnvVars,
  validatePluginEnvVars,
  getConfigFilePath,
  loadConfig,
  saveConfig,
  checkPluginRequirements,
  getPluginStatus,
  copyDir,
  copyTemplate,
  copyClientDist,
  getVersion,
  getCliInstallTag,
  isUtf8Locale,
  getLatestCliVersion,
  showUpdateNotification,
  checkAndShowUpdateNotification,
  displayBanner,
  isValidPostgresUrl,
  getElizaDirectories,
  setupEnvFile,
  ensureElizaDir,
  setupPgLite,
  storePostgresUrl,
  storePgliteDataDir,
  promptAndStorePostgresUrl,
  isValidOpenAIKey,
  isValidAnthropicKey,
  isValidGoogleKey,
  storeOpenAIKey,
  storeGoogleKey,
  storeAnthropicKey,
  promptAndStoreOpenAIKey,
  promptAndStoreAnthropicKey,
  isValidOllamaEndpoint,
  storeOllamaConfig,
  promptAndStoreOllamaEmbeddingConfig,
  promptAndStoreOllamaConfig,
  promptAndStoreGoogleKey,
  isValidOpenRouterKey,
  storeOpenRouterKey,
  promptAndStoreOpenRouterKey,
  configureDatabaseSettings,
  rawConfigSchema,
  configSchema,
  resolveConfigPaths,
  loadEnvironment,
  mergeProcessEnvWithTemplate,
  formatEnvFileWithTemplate,
  getPackageVersion,
  getLocalPackages,
  getPackageInfo,
  ensureElizaDir2,
  getRegistrySettings,
  saveRegistrySettings,
  getEnvVar,
  setEnvVar,
  getGitHubToken,
  setGitHubToken,
  saveRegistryCache,
  getLocalRegistryIndex,
  getRegistryIndex,
  normalizePluginName,
  getPluginRepository,
  repoHasBranch,
  getBestBranch,
  listPluginsByType,
  getPluginMetadata,
  getPluginVersion,
  getPluginTags,
  getPluginCategories,
  getAvailableDatabases,
  getPackageDetails,
  getBestPluginVersion,
  checkDataDir,
  initializeDataDir,
  validateDataDir,
  validateGitHubToken,
  forkExists,
  forkRepository,
  branchExists,
  createBranch,
  getFileContent,
  updateFile,
  createPullRequest,
  getAuthenticatedUser,
  getGitHubCredentials,
  saveGitHubCredentials,
  ensureDirectory,
  createGitHubRepository,
  pushToGitHub,
  handleError,
  checkServer,
  displayAgent,
  logHeader,
  detectPluginContext,
  ensurePluginBuilt,
  provideLocalPluginGuidance,
  loadPluginModule,
  getPackageManager,
  isGlobalInstallation,
  isRunningViaNpx,
  isRunningViaBunx,
  getInstallCommand,
  removeFromBunLock,
  executeInstallation,
  buildGitHubSpecifier,
  executeInstallationWithFallback,
  fetchPluginRegistry,
  installPlugin,
  isPortFree,
  findNextAvailablePort,
  testPublishToNpm,
  testPublishToGitHub,
  publishToNpm,
  publishToGitHub,
  resolveImport,
  TestRunner,
  getAgents,
  resolveAgentId,
  getAgent,
  removeAgent,
  clearAgentMemories,
  setAgentConfig,
  startAgent,
  stopAgent,
  agent
};
